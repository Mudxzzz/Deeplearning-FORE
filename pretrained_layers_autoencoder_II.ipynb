{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained_layers_autoencoder-II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/keras/blob/main/pretrained_layers_autoencoder_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hUNNtAJhWE7"
      },
      "source": [
        "# Last amended: 21st Jan, 2021\r\n",
        "# Myfolder:\r\n",
        "#\r\n",
        "# Objectives\r\n",
        "#            i)  Building autoencoder using Model class subclassing\r\n",
        "#            ii) Training autoencoder with gaussian noise added \r\n",
        "#           iii) Using pre-trained autoencoder layers in a classifier\r\n",
        "#           iv)  Comparing Classifer performance with and without pre-trained \r\n",
        "#            v)  Using keras model as a layer\r\n",
        "#            vi) A pre-trained model using autoencoder-with-noise added gives\r\n",
        "#                better classification\r\n",
        "#\r\n",
        "#\r\n",
        "# Ref: https://www.tensorflow.org/tutorials/generative/autoencoder#first_example_basic_autoencoder\r\n",
        "#      https://www.tensorflow.org/tutorials/generative/autoencoder#third_example_anomaly_detection\r\n",
        "#      Practical Recommendations for Gradient-Based Training of DeepArchitectures by Yoshua Bengio\r\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoU-r_hoe4qD"
      },
      "source": [
        "# 1.0 Import libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZygQFzuHUo4"
      },
      "source": [
        "# 1.1 Display outputs from multiple commands in a colab cell\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR9cqRU3e--E",
        "outputId": "2e42bb71-67cc-4c14-fff1-7ee8eb5e655a"
      },
      "source": [
        "# 2.0 Get fashion mnist data\r\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Normalize data\r\n",
        "x_train = x_train.astype('float32') / 255.\r\n",
        "x_test = x_test.astype('float32') / 255.\r\n",
        "\r\n",
        "# Data shape\r\n",
        "print (x_train.shape)\r\n",
        "print (x_test.shape)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1WD0i_-Gwfl"
      },
      "source": [
        "# 2.1 Reshape data for feeding it to NN model\r\n",
        "x_train = x_train.reshape((-1, 784))\r\n",
        "x_test = x_test.reshape((-1, 784))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgm7Ld0UeAVh"
      },
      "source": [
        "# 2.2 Design an Autoencoder with Subclassing\r\n",
        "#     Encoder has noise added\r\n",
        "#     Ref: https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n",
        "#     Page 313, Book: Hands-on Machine Learning witgh Scitkit-Learn, Keras, and Tensorflow\r\n",
        "\r\n",
        "latent_dim = 64 \r\n",
        "class Autoencoder(Model):\r\n",
        "\r\n",
        "  # 2.2.1 Design all layers\r\n",
        "  def __init__(self, latent_dim, noise_level=0.1):\r\n",
        "    super(Autoencoder, self).__init__()\r\n",
        "    self.latent_dim = latent_dim\r\n",
        "    self.noise_level = noise_level\r\n",
        "    # 2.2.2 This is our encoder\r\n",
        "    self.encoder = tf.keras.Sequential(\r\n",
        "                                        [\r\n",
        "                                          layers.Input(shape=(784,)),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.GaussianNoise(0.1),   # Add some noise\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu')\r\n",
        "                                        ]\r\n",
        "                                       )\r\n",
        "    # 2.2.3 This is our decoder\r\n",
        "    self.decoder = tf.keras.Sequential(\r\n",
        "                                        [\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(784, activation='sigmoid'),\r\n",
        "                                          #layers.Reshape((28, 28))\r\n",
        "                                         ]\r\n",
        "                                       )\r\n",
        "  \r\n",
        "  # 2.2.4 Call function with just one parameter    \r\n",
        "  def call(self, inputs):\r\n",
        "    encoded = self.encoder(inputs)\r\n",
        "    decoded = self.decoder(encoded)\r\n",
        "    return decoded\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVI1uxltfQzP",
        "outputId": "361dacf6-e176-4d98-d1d0-6e4561568795"
      },
      "source": [
        "# 3.0 Instantiate, compile and train autoencoder\r\n",
        "autoencoder = Autoencoder(100, 0.1)\r\n",
        "autoencoder.compile(optimizer='adam', loss=\"mse\")\r\n",
        "autoencoder.fit(x_train, x_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.0388 - val_loss: 0.0176\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0169 - val_loss: 0.0144\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0141 - val_loss: 0.0130\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0128 - val_loss: 0.0120\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0120 - val_loss: 0.0114\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0114 - val_loss: 0.0109\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0109 - val_loss: 0.0107\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0106 - val_loss: 0.0102\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0102 - val_loss: 0.0101\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0101 - val_loss: 0.0098\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0098 - val_loss: 0.0097\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0097 - val_loss: 0.0096\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0095 - val_loss: 0.0095\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0093 - val_loss: 0.0094\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0092 - val_loss: 0.0092\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0091 - val_loss: 0.0092\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0090 - val_loss: 0.0089\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0089 - val_loss: 0.0089\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0088 - val_loss: 0.0090\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0087 - val_loss: 0.0086\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0086 - val_loss: 0.0087\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0086 - val_loss: 0.0088\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0086 - val_loss: 0.0086\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0085 - val_loss: 0.0085\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - val_loss: 0.0085\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - val_loss: 0.0087\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - val_loss: 0.0085\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - val_loss: 0.0084\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0082 - val_loss: 0.0083\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0082 - val_loss: 0.0083\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0081 - val_loss: 0.0081\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0081\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0080\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0083\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0081\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0079\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0080 - val_loss: 0.0081\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - val_loss: 0.0080\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - val_loss: 0.0081\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - val_loss: 0.0080\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0076\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0076\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0077\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0075\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0075\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0077\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0075\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0077\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0075\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0073 - val_loss: 0.0074\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - val_loss: 0.0075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f151a08e7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfoYTxPNdX1d"
      },
      "source": [
        "# 3.1 Layer-wise summary\r\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgTclMTsdd1x"
      },
      "source": [
        "# 3.2 Just look at layers\r\n",
        "autoencoder.layers \r\n",
        "autoencoder.layers[-2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu4uMR9IU4vf"
      },
      "source": [
        "# 4.0 Design an Autoencoder with Subclassing\r\n",
        "#     BUT Encoder has NO noise added\r\n",
        "\r\n",
        "latent_dim = 64 \r\n",
        "class Autoencoder_n(Model):\r\n",
        "\r\n",
        "  # 4.0.1 Design all layers\r\n",
        "  def __init__(self, latent_dim, noise_level=0.1):\r\n",
        "    super(Autoencoder_n, self).__init__()\r\n",
        "    self.latent_dim = latent_dim\r\n",
        "    self.noise_level = noise_level\r\n",
        "    # 4.0.2 This is our encoder\r\n",
        "    self.encoder = tf.keras.Sequential(\r\n",
        "                                        [\r\n",
        "                                          layers.Input(shape=(784,)),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          #layers.GaussianNoise(0.1),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu')\r\n",
        "                                        ]\r\n",
        "                                       )\r\n",
        "    # 4.0.3 This is our decoder\r\n",
        "    self.decoder = tf.keras.Sequential(\r\n",
        "                                        [\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(self.latent_dim, activation='relu'),\r\n",
        "                                          layers.Dense(784, activation='sigmoid'),\r\n",
        "                                          #layers.Reshape((28, 28))\r\n",
        "                                         ]\r\n",
        "                                       )\r\n",
        "  \r\n",
        "  # 4.0.4 Call function with just one parameter    \r\n",
        "  def call(self, inputs):\r\n",
        "    encoded = self.encoder(inputs)\r\n",
        "    decoded = self.decoder(encoded)\r\n",
        "    return decoded\r\n",
        "\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFcbBWjVQGT",
        "outputId": "42719a02-4c73-471b-d6a8-89f8a0ec2d11"
      },
      "source": [
        "# 5.0 As our model has been built using subclassing API,\r\n",
        "#     to intantiate the model, we have to fit it.\r\n",
        "#     Of course, this training is of no use as we will\r\n",
        "#     replace the encoder weights by the learned weights\r\n",
        "#     of earlier autoencoder\r\n",
        "\r\n",
        "autoencoder_n = Autoencoder_n(100)\r\n",
        "autoencoder_n.compile(optimizer='adam', loss=\"mse\")\r\n",
        "autoencoder_n.fit(x_train, x_train,\r\n",
        "                epochs=10,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))\r\n",
        "\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0379 - val_loss: 0.0173\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0164 - val_loss: 0.0142\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0138 - val_loss: 0.0128\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0126 - val_loss: 0.0120\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0118 - val_loss: 0.0115\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0113 - val_loss: 0.0111\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0109 - val_loss: 0.0107\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0105 - val_loss: 0.0105\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0102 - val_loss: 0.0102\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0099 - val_loss: 0.0099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f150a78b4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMkLkswaWxY2"
      },
      "source": [
        "# 5.1 Replace 'encoder' weights of autoencoder_n\r\n",
        "autoencoder_n.layers[1].set_weights(autoencoder.layers[1].get_weights())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8eSAC0NfQ6i"
      },
      "source": [
        "# 6.0 So now we have two autoencoders. One which was trained with noise added\r\n",
        "#     to input. And the other whose 'encoder' has the same weights as of earlier\r\n",
        "#     autoencoder. BUT this autoencoder does NOT have, so-to-say GaussianNoise layer."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEGs9nThiPr9"
      },
      "source": [
        "# Classification\r\n",
        "Using autoencoder pre-trained weights while performing classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36gyv5nIODO"
      },
      "source": [
        "# 7.0 Define Classification model function\r\n",
        "#     \r\n",
        "def class_model(trainable = False):\r\n",
        "  model1 = tf.keras.models.Sequential()\r\n",
        "  # 7.1 Add autoencoder_n as a layer\r\n",
        "  #     But only the 'encoder' part\r\n",
        "  #     WE ADD THAT autoencoder that\r\n",
        "  #     DOES NOT have gauusian noise layer\r\n",
        "  model1.add(autoencoder_n.layers[-2])\r\n",
        "  # 7.2 This is the output layer of our model\r\n",
        "  model1.add(layers.Dense(10,activation = \"softmax\"))\r\n",
        "  # 7.3 No training for autoencoder\r\n",
        "  autoencoder.layers[-2].trainable = trainable\r\n",
        "  model1.layers[0].trainable = trainable\r\n",
        "  return model1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJyB92zeJVL2",
        "outputId": "d278eb52-760a-4623-bfa3-c681568ad001"
      },
      "source": [
        "# 8.0 Instantiate classification model and train it\r\n",
        "model1 = class_model(False)\r\n",
        "# 8.1\r\n",
        "model1.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "# 8.2\r\n",
        "model1.fit(x_train, y_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, y_test)\r\n",
        "                )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1034 - accuracy: 0.6360 - val_loss: 0.5347 - val_accuracy: 0.8080\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4997 - accuracy: 0.8224 - val_loss: 0.5013 - val_accuracy: 0.8248\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4712 - accuracy: 0.8324 - val_loss: 0.4855 - val_accuracy: 0.8288\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4582 - accuracy: 0.8379 - val_loss: 0.4843 - val_accuracy: 0.8295\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4483 - accuracy: 0.8398 - val_loss: 0.4857 - val_accuracy: 0.8296\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4425 - accuracy: 0.8430 - val_loss: 0.4783 - val_accuracy: 0.8296\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4439 - accuracy: 0.8447 - val_loss: 0.4708 - val_accuracy: 0.8367\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4371 - accuracy: 0.8470 - val_loss: 0.4711 - val_accuracy: 0.8323\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4389 - accuracy: 0.8470 - val_loss: 0.4713 - val_accuracy: 0.8343\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4320 - accuracy: 0.8490 - val_loss: 0.4698 - val_accuracy: 0.8361\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4302 - accuracy: 0.8493 - val_loss: 0.4738 - val_accuracy: 0.8368\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4292 - accuracy: 0.8513 - val_loss: 0.4661 - val_accuracy: 0.8368\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4313 - accuracy: 0.8501 - val_loss: 0.4853 - val_accuracy: 0.8313\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4353 - accuracy: 0.8488 - val_loss: 0.4716 - val_accuracy: 0.8355\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4319 - accuracy: 0.8500 - val_loss: 0.4707 - val_accuracy: 0.8359\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4285 - accuracy: 0.8504 - val_loss: 0.4740 - val_accuracy: 0.8370\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4332 - accuracy: 0.8481 - val_loss: 0.4692 - val_accuracy: 0.8385\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4306 - accuracy: 0.8517 - val_loss: 0.4697 - val_accuracy: 0.8379\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4243 - accuracy: 0.8519 - val_loss: 0.4720 - val_accuracy: 0.8349\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4236 - accuracy: 0.8531 - val_loss: 0.4695 - val_accuracy: 0.8375\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4286 - accuracy: 0.8517 - val_loss: 0.4789 - val_accuracy: 0.8356\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4355 - accuracy: 0.8502 - val_loss: 0.4744 - val_accuracy: 0.8388\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4365 - accuracy: 0.8504 - val_loss: 0.4784 - val_accuracy: 0.8365\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4328 - accuracy: 0.8497 - val_loss: 0.4728 - val_accuracy: 0.8366\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4351 - accuracy: 0.8516 - val_loss: 0.4724 - val_accuracy: 0.8368\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4317 - accuracy: 0.8513 - val_loss: 0.4694 - val_accuracy: 0.8396\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4316 - accuracy: 0.8520 - val_loss: 0.4703 - val_accuracy: 0.8420\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4252 - accuracy: 0.8527 - val_loss: 0.4790 - val_accuracy: 0.8365\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4288 - accuracy: 0.8531 - val_loss: 0.4770 - val_accuracy: 0.8394\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4317 - accuracy: 0.8515 - val_loss: 0.4755 - val_accuracy: 0.8358\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4293 - accuracy: 0.8520 - val_loss: 0.4758 - val_accuracy: 0.8361\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4315 - accuracy: 0.8509 - val_loss: 0.4733 - val_accuracy: 0.8403\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4301 - accuracy: 0.8513 - val_loss: 0.4756 - val_accuracy: 0.8386\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4321 - accuracy: 0.8523 - val_loss: 0.4748 - val_accuracy: 0.8372\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4316 - accuracy: 0.8514 - val_loss: 0.4729 - val_accuracy: 0.8406\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4299 - accuracy: 0.8528 - val_loss: 0.4714 - val_accuracy: 0.8402\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4315 - accuracy: 0.8528 - val_loss: 0.4738 - val_accuracy: 0.8396\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4342 - accuracy: 0.8527 - val_loss: 0.4813 - val_accuracy: 0.8378\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4299 - accuracy: 0.8543 - val_loss: 0.4705 - val_accuracy: 0.8402\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4355 - accuracy: 0.8526 - val_loss: 0.4718 - val_accuracy: 0.8390\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4374 - accuracy: 0.8520 - val_loss: 0.4724 - val_accuracy: 0.8391\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4359 - accuracy: 0.8533 - val_loss: 0.4759 - val_accuracy: 0.8382\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4352 - accuracy: 0.8508 - val_loss: 0.4799 - val_accuracy: 0.8365\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4326 - accuracy: 0.8517 - val_loss: 0.4740 - val_accuracy: 0.8395\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4284 - accuracy: 0.8554 - val_loss: 0.4718 - val_accuracy: 0.8391\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4362 - accuracy: 0.8525 - val_loss: 0.4761 - val_accuracy: 0.8392\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4254 - accuracy: 0.8540 - val_loss: 0.4828 - val_accuracy: 0.8334\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4352 - accuracy: 0.8517 - val_loss: 0.4803 - val_accuracy: 0.8382\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4389 - accuracy: 0.8526 - val_loss: 0.4750 - val_accuracy: 0.8393\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4301 - accuracy: 0.8529 - val_loss: 0.4709 - val_accuracy: 0.8414\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4356 - accuracy: 0.8507 - val_loss: 0.4935 - val_accuracy: 0.8311\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4413 - accuracy: 0.8514 - val_loss: 0.4771 - val_accuracy: 0.8416\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4326 - accuracy: 0.8515 - val_loss: 0.4744 - val_accuracy: 0.8387\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4332 - accuracy: 0.8536 - val_loss: 0.4779 - val_accuracy: 0.8413\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4372 - accuracy: 0.8502 - val_loss: 0.4773 - val_accuracy: 0.8387\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4361 - accuracy: 0.8516 - val_loss: 0.4768 - val_accuracy: 0.8388\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4356 - accuracy: 0.8512 - val_loss: 0.4755 - val_accuracy: 0.8385\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4263 - accuracy: 0.8544 - val_loss: 0.4730 - val_accuracy: 0.8401\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4322 - accuracy: 0.8530 - val_loss: 0.4768 - val_accuracy: 0.8391\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4343 - accuracy: 0.8537 - val_loss: 0.4771 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4346 - accuracy: 0.8547 - val_loss: 0.4729 - val_accuracy: 0.8420\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4316 - accuracy: 0.8526 - val_loss: 0.4753 - val_accuracy: 0.8401\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4447 - accuracy: 0.8515 - val_loss: 0.4838 - val_accuracy: 0.8346\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4372 - accuracy: 0.8518 - val_loss: 0.4752 - val_accuracy: 0.8413\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4326 - accuracy: 0.8547 - val_loss: 0.4788 - val_accuracy: 0.8396\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4308 - accuracy: 0.8536 - val_loss: 0.4831 - val_accuracy: 0.8387\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4298 - accuracy: 0.8529 - val_loss: 0.4785 - val_accuracy: 0.8401\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4377 - accuracy: 0.8540 - val_loss: 0.4735 - val_accuracy: 0.8418\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4437 - accuracy: 0.8522 - val_loss: 0.4879 - val_accuracy: 0.8371\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4346 - accuracy: 0.8535 - val_loss: 0.4837 - val_accuracy: 0.8375\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4373 - accuracy: 0.8543 - val_loss: 0.4800 - val_accuracy: 0.8402\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4466 - accuracy: 0.8519 - val_loss: 0.4812 - val_accuracy: 0.8369\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4413 - accuracy: 0.8510 - val_loss: 0.4794 - val_accuracy: 0.8397\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4390 - accuracy: 0.8551 - val_loss: 0.4781 - val_accuracy: 0.8399\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4294 - accuracy: 0.8560 - val_loss: 0.4755 - val_accuracy: 0.8411\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4363 - accuracy: 0.8512 - val_loss: 0.4863 - val_accuracy: 0.8393\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4327 - accuracy: 0.8540 - val_loss: 0.4888 - val_accuracy: 0.8376\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4424 - accuracy: 0.8524 - val_loss: 0.4809 - val_accuracy: 0.8378\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4392 - accuracy: 0.8537 - val_loss: 0.4825 - val_accuracy: 0.8377\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4381 - accuracy: 0.8510 - val_loss: 0.4815 - val_accuracy: 0.8422\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4347 - accuracy: 0.8526 - val_loss: 0.4810 - val_accuracy: 0.8393\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4326 - accuracy: 0.8530 - val_loss: 0.4914 - val_accuracy: 0.8367\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4310 - accuracy: 0.8543 - val_loss: 0.4888 - val_accuracy: 0.8378\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4388 - accuracy: 0.8530 - val_loss: 0.4806 - val_accuracy: 0.8415\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4349 - accuracy: 0.8525 - val_loss: 0.4870 - val_accuracy: 0.8378\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4343 - accuracy: 0.8562 - val_loss: 0.4802 - val_accuracy: 0.8410\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.8530 - val_loss: 0.4838 - val_accuracy: 0.8357\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4377 - accuracy: 0.8533 - val_loss: 0.4843 - val_accuracy: 0.8370\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4335 - accuracy: 0.8545 - val_loss: 0.4768 - val_accuracy: 0.8393\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4433 - accuracy: 0.8518 - val_loss: 0.4822 - val_accuracy: 0.8386\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4368 - accuracy: 0.8536 - val_loss: 0.4855 - val_accuracy: 0.8355\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4403 - accuracy: 0.8529 - val_loss: 0.4854 - val_accuracy: 0.8381\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4342 - accuracy: 0.8554 - val_loss: 0.4803 - val_accuracy: 0.8414\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4320 - accuracy: 0.8537 - val_loss: 0.4784 - val_accuracy: 0.8416\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4367 - accuracy: 0.8554 - val_loss: 0.4818 - val_accuracy: 0.8388\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4361 - accuracy: 0.8544 - val_loss: 0.4869 - val_accuracy: 0.8354\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4324 - accuracy: 0.8532 - val_loss: 0.4824 - val_accuracy: 0.8392\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4394 - accuracy: 0.8518 - val_loss: 0.4796 - val_accuracy: 0.8422\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4381 - accuracy: 0.8532 - val_loss: 0.4858 - val_accuracy: 0.8395\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4356 - accuracy: 0.8535 - val_loss: 0.4800 - val_accuracy: 0.8407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f150a6574e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0_gpKiokzp9",
        "outputId": "22af28de-fad6-4cd0-a557-0d369faa97ae"
      },
      "source": [
        "# 8.3 Evaluate model\r\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.8407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4799702763557434, 0.8406999707221985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi0kq3elIpq9",
        "outputId": "6c55cd6f-6ac7-4b00-e2c9-6d3fbc987849"
      },
      "source": [
        "# 8.4 Also get its summary\r\n",
        "model1.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_10 (Sequential)   (None, 100)               98700     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 99,710\n",
            "Trainable params: 1,010\n",
            "Non-trainable params: 98,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mYAfU_zObRU",
        "outputId": "eefd07bb-8552-4c1f-de7d-425115979d37"
      },
      "source": [
        "# 9.0 Run the classification model again but \r\n",
        "#     this time train the autoencoder layer\r\n",
        "\r\n",
        "model2 = class_model(True)\r\n",
        "# 9.1\r\n",
        "model2.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "# 9.2\r\n",
        "model2.fit(x_train, y_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, y_test)\r\n",
        "                )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6244 - accuracy: 0.7816 - val_loss: 0.4585 - val_accuracy: 0.8394\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3732 - accuracy: 0.8646 - val_loss: 0.4148 - val_accuracy: 0.8595\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3532 - accuracy: 0.8742 - val_loss: 0.4347 - val_accuracy: 0.8615\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3383 - accuracy: 0.8791 - val_loss: 0.4175 - val_accuracy: 0.8649\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3444 - accuracy: 0.8811 - val_loss: 0.4249 - val_accuracy: 0.8651\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3358 - accuracy: 0.8846 - val_loss: 0.5268 - val_accuracy: 0.8440\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3329 - accuracy: 0.8825 - val_loss: 0.5046 - val_accuracy: 0.8459\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3356 - accuracy: 0.8852 - val_loss: 0.5522 - val_accuracy: 0.8508\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3392 - accuracy: 0.8864 - val_loss: 0.5202 - val_accuracy: 0.8626\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3413 - accuracy: 0.8847 - val_loss: 0.6126 - val_accuracy: 0.8220\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3332 - accuracy: 0.8873 - val_loss: 0.5943 - val_accuracy: 0.8596\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3312 - accuracy: 0.8887 - val_loss: 0.7360 - val_accuracy: 0.8613\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3384 - accuracy: 0.8911 - val_loss: 0.6652 - val_accuracy: 0.8530\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3273 - accuracy: 0.8921 - val_loss: 0.6009 - val_accuracy: 0.8537\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3410 - accuracy: 0.8909 - val_loss: 0.5628 - val_accuracy: 0.8707\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3417 - accuracy: 0.8898 - val_loss: 0.5428 - val_accuracy: 0.8668\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3354 - accuracy: 0.8928 - val_loss: 0.6493 - val_accuracy: 0.8666\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3357 - accuracy: 0.8946 - val_loss: 0.6131 - val_accuracy: 0.8596\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3212 - accuracy: 0.8965 - val_loss: 0.5663 - val_accuracy: 0.8662\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3285 - accuracy: 0.8929 - val_loss: 0.6367 - val_accuracy: 0.8664\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3207 - accuracy: 0.8955 - val_loss: 0.6291 - val_accuracy: 0.8729\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3202 - accuracy: 0.8939 - val_loss: 0.7526 - val_accuracy: 0.8636\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3230 - accuracy: 0.8950 - val_loss: 0.7447 - val_accuracy: 0.8419\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3347 - accuracy: 0.8949 - val_loss: 0.8716 - val_accuracy: 0.8675\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3240 - accuracy: 0.8977 - val_loss: 0.7793 - val_accuracy: 0.8514\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3210 - accuracy: 0.8970 - val_loss: 0.8448 - val_accuracy: 0.8192\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3249 - accuracy: 0.8978 - val_loss: 0.8706 - val_accuracy: 0.8665\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3436 - accuracy: 0.8982 - val_loss: 0.7756 - val_accuracy: 0.8676\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3332 - accuracy: 0.8983 - val_loss: 0.9045 - val_accuracy: 0.8592\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3276 - accuracy: 0.8979 - val_loss: 0.8033 - val_accuracy: 0.8700\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3186 - accuracy: 0.8998 - val_loss: 0.9055 - val_accuracy: 0.8614\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3260 - accuracy: 0.8976 - val_loss: 0.9516 - val_accuracy: 0.8601\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3301 - accuracy: 0.8992 - val_loss: 0.8809 - val_accuracy: 0.8736\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3205 - accuracy: 0.9015 - val_loss: 0.9765 - val_accuracy: 0.8721\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3219 - accuracy: 0.9006 - val_loss: 1.0155 - val_accuracy: 0.8651\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3353 - accuracy: 0.9006 - val_loss: 1.1994 - val_accuracy: 0.8734\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3246 - accuracy: 0.9011 - val_loss: 1.1986 - val_accuracy: 0.8576\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3596 - accuracy: 0.9012 - val_loss: 1.1752 - val_accuracy: 0.8506\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3233 - accuracy: 0.9014 - val_loss: 1.2010 - val_accuracy: 0.8592\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3430 - accuracy: 0.9019 - val_loss: 0.9799 - val_accuracy: 0.8541\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.9005 - val_loss: 0.9718 - val_accuracy: 0.8560\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.9013 - val_loss: 1.0823 - val_accuracy: 0.8724\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.9019 - val_loss: 1.2174 - val_accuracy: 0.8691\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.9000 - val_loss: 1.2777 - val_accuracy: 0.8656\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3387 - accuracy: 0.9014 - val_loss: 1.0850 - val_accuracy: 0.8694\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3467 - accuracy: 0.9007 - val_loss: 1.2704 - val_accuracy: 0.8728\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3298 - accuracy: 0.9040 - val_loss: 1.0155 - val_accuracy: 0.8604\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3459 - accuracy: 0.9011 - val_loss: 1.3505 - val_accuracy: 0.8608\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3336 - accuracy: 0.9020 - val_loss: 1.2738 - val_accuracy: 0.8682\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3369 - accuracy: 0.9015 - val_loss: 1.5368 - val_accuracy: 0.8730\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3556 - accuracy: 0.9029 - val_loss: 1.3731 - val_accuracy: 0.8647\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3502 - accuracy: 0.9000 - val_loss: 1.3213 - val_accuracy: 0.8513\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3572 - accuracy: 0.9031 - val_loss: 1.3454 - val_accuracy: 0.8620\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3461 - accuracy: 0.8998 - val_loss: 1.5360 - val_accuracy: 0.8470\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3536 - accuracy: 0.9014 - val_loss: 1.6508 - val_accuracy: 0.8640\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3407 - accuracy: 0.9015 - val_loss: 1.4989 - val_accuracy: 0.8470\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.9068 - val_loss: 1.4113 - val_accuracy: 0.8665\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3731 - accuracy: 0.9023 - val_loss: 1.6882 - val_accuracy: 0.8688\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3355 - accuracy: 0.9028 - val_loss: 1.4664 - val_accuracy: 0.8750\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3468 - accuracy: 0.9011 - val_loss: 1.9986 - val_accuracy: 0.8746\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3622 - accuracy: 0.9041 - val_loss: 1.6641 - val_accuracy: 0.8631\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3394 - accuracy: 0.9037 - val_loss: 1.6381 - val_accuracy: 0.8701\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3568 - accuracy: 0.9014 - val_loss: 1.8610 - val_accuracy: 0.8694\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3607 - accuracy: 0.9017 - val_loss: 1.9585 - val_accuracy: 0.8717\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3739 - accuracy: 0.9008 - val_loss: 1.7879 - val_accuracy: 0.8548\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3476 - accuracy: 0.8999 - val_loss: 2.0897 - val_accuracy: 0.8486\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3320 - accuracy: 0.9047 - val_loss: 2.1456 - val_accuracy: 0.8451\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3487 - accuracy: 0.9056 - val_loss: 1.9496 - val_accuracy: 0.8592\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3643 - accuracy: 0.9029 - val_loss: 2.1878 - val_accuracy: 0.8614\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3506 - accuracy: 0.9031 - val_loss: 2.2220 - val_accuracy: 0.8736\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3710 - accuracy: 0.9017 - val_loss: 1.8499 - val_accuracy: 0.8630\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3541 - accuracy: 0.9026 - val_loss: 2.0414 - val_accuracy: 0.8702\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3504 - accuracy: 0.9040 - val_loss: 2.2773 - val_accuracy: 0.8526\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3532 - accuracy: 0.9028 - val_loss: 2.0409 - val_accuracy: 0.8678\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3658 - accuracy: 0.9037 - val_loss: 2.5871 - val_accuracy: 0.8640\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4278 - accuracy: 0.8991 - val_loss: 2.2861 - val_accuracy: 0.8546\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3583 - accuracy: 0.9041 - val_loss: 2.5479 - val_accuracy: 0.8659\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3928 - accuracy: 0.9040 - val_loss: 2.1324 - val_accuracy: 0.8671\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3573 - accuracy: 0.9034 - val_loss: 2.2528 - val_accuracy: 0.8513\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3438 - accuracy: 0.9019 - val_loss: 2.2213 - val_accuracy: 0.8626\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3831 - accuracy: 0.9032 - val_loss: 2.7800 - val_accuracy: 0.8640\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3742 - accuracy: 0.9038 - val_loss: 2.6656 - val_accuracy: 0.8530\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3836 - accuracy: 0.9044 - val_loss: 2.6986 - val_accuracy: 0.8599\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4097 - accuracy: 0.9022 - val_loss: 3.4227 - val_accuracy: 0.8672\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3790 - accuracy: 0.9020 - val_loss: 2.2984 - val_accuracy: 0.8578\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3661 - accuracy: 0.9002 - val_loss: 2.4154 - val_accuracy: 0.8666\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3923 - accuracy: 0.8999 - val_loss: 2.4707 - val_accuracy: 0.8542\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3985 - accuracy: 0.9010 - val_loss: 3.0400 - val_accuracy: 0.8616\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3890 - accuracy: 0.9020 - val_loss: 3.0526 - val_accuracy: 0.8514\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3743 - accuracy: 0.9038 - val_loss: 2.5794 - val_accuracy: 0.8625\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3835 - accuracy: 0.9017 - val_loss: 2.9982 - val_accuracy: 0.8661\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4051 - accuracy: 0.8985 - val_loss: 2.8040 - val_accuracy: 0.8611\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4140 - accuracy: 0.8997 - val_loss: 3.0887 - val_accuracy: 0.8686\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3954 - accuracy: 0.9015 - val_loss: 2.5738 - val_accuracy: 0.8657\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3750 - accuracy: 0.9026 - val_loss: 2.8658 - val_accuracy: 0.8471\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4522 - accuracy: 0.9002 - val_loss: 3.4811 - val_accuracy: 0.8477\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3882 - accuracy: 0.9034 - val_loss: 2.8410 - val_accuracy: 0.8610\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4196 - accuracy: 0.9029 - val_loss: 3.0421 - val_accuracy: 0.8614\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3734 - accuracy: 0.9055 - val_loss: 3.3898 - val_accuracy: 0.8671\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4729 - accuracy: 0.8988 - val_loss: 2.9957 - val_accuracy: 0.8628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1509567160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NIL4F3OgCq",
        "outputId": "f050cadf-e79f-451d-da95-e7b788c9978c"
      },
      "source": [
        "# 9.3 Evaluate the model\r\n",
        "#    Observe that a pre-trained model using\r\n",
        "#    autoencoder gives better classification\r\n",
        "model2.evaluate(x_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 2.9957 - accuracy: 0.8628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.995737314224243, 0.8628000020980835]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSt7xaHkjduo",
        "outputId": "b625bb88-fc84-46ca-c9c2-ad23acb8758e"
      },
      "source": [
        "# 10.0 If you evaluate model1 again, we get very low accuracy\r\n",
        "#     as autoencoder weights have changed\r\n",
        "model1.evaluate(x_test,y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 140.0505 - accuracy: 0.0836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[140.05047607421875, 0.0835999995470047]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ91niuYxFM1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}