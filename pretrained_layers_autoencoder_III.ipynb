{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained_layers_autoencoder-III.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/keras/blob/main/pretrained_layers_autoencoder_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hUNNtAJhWE7"
      },
      "source": [
        "# Last amended: 22nd Jan, 2021\r\n",
        "# Myfolder: https://github.com/harnalashok/keras\r\n",
        "#\r\n",
        "# Objectives\r\n",
        "#            i)   Building autoencoder using Model class subclassing\r\n",
        "#        ==>ii)  Building autoencoder using Functional API   <==\r\n",
        "#           iii)  Training autoencoder with gaussian noise added \r\n",
        "#            iv)  Using pre-trained autoencoder layers in a classifier\r\n",
        "#             v)  Comparing Classifer performance with and without pre-trained \r\n",
        "#            vi)  Using keras model as a layer\r\n",
        "#           vii)  A pre-trained model using autoencoder-with-noise added gives\r\n",
        "#                 better classification\r\n",
        "#\r\n",
        "#\r\n",
        "# Ref: https://www.tensorflow.org/tutorials/generative/autoencoder#first_example_basic_autoencoder\r\n",
        "#      https://www.tensorflow.org/tutorials/generative/autoencoder#third_example_anomaly_detection\r\n",
        "#      Practical Recommendations for Gradient-Based Training of DeepArchitectures by Yoshua Bengio\r\n",
        "#      https://www.tensorflow.org/guide/keras/save_and_serialize#saving_loading_only_the_models_weights_values\r\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoU-r_hoe4qD"
      },
      "source": [
        "# 1.0 Import libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZygQFzuHUo4"
      },
      "source": [
        "# 1.1 Display outputs from multiple commands in a colab cell\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR9cqRU3e--E",
        "outputId": "36560e89-7e47-4031-ca02-4379d482d723"
      },
      "source": [
        "# 2.0 Get fashion mnist data\r\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "# Normalize data\r\n",
        "x_train = x_train.astype('float32') / 255.\r\n",
        "x_test = x_test.astype('float32') / 255.\r\n",
        "\r\n",
        "# Data shape\r\n",
        "print (x_train.shape)\r\n",
        "print (x_test.shape)\r\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1WD0i_-Gwfl"
      },
      "source": [
        "# 2.1 Reshape data for feeding it to NN model\r\n",
        "x_train = x_train.reshape((-1, 784))\r\n",
        "x_test = x_test.reshape((-1, 784))"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgm7Ld0UeAVh"
      },
      "source": [
        "# 2.2 Design an Autoencoder with Subclassing\r\n",
        "#     We use Functional Model API\r\n",
        "#     Encoder has noise added\r\n",
        "#     Ref: https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n",
        "#     Page 313, Book: Hands-on Machine Learning witgh Scitkit-Learn, Keras, and Tensorflow\r\n",
        "\r\n",
        "latent_dim = 64 \r\n",
        "class Autoencoder(Model):\r\n",
        "\r\n",
        "  # 2.2.1 Design all layers\r\n",
        "  def __init__(self, latent_dim, noise_level=0.1):\r\n",
        "    super(Autoencoder, self).__init__()\r\n",
        "\r\n",
        "    self.latent_dim = latent_dim\r\n",
        "    self.noise_level = noise_level\r\n",
        "\r\n",
        "    # 2.2.2 Define just layers. \r\n",
        "    #layers.Input(shape=(784,))   Inputs will be supplied later\r\n",
        "    self.en_ld1 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.en_ld2 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.en_lg  = layers.GaussianNoise(0.1)   # Add some noise\r\n",
        "    self.en_ldo = layers.Dense(self.latent_dim, activation='relu', name = \"encoder\")\r\n",
        "\r\n",
        "    # 2.2.3 This is our decoder\r\n",
        "    self.de_ld1 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.de_ld2 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.de_ld3 = layers.Dense(784, activation='sigmoid',name = \"decoder\")\r\n",
        "    #layers.Reshape((28, 28))\r\n",
        "\r\n",
        "  \r\n",
        "  # 2.2.4 Call function with just one parameter, inputs    \r\n",
        "  def call(self, inputs):\r\n",
        "    # 2.3.5: Encoder part\r\n",
        "    x = self.en_ld1(inputs)\r\n",
        "    x = self.en_ld2(x)\r\n",
        "    x = self.en_lg(x)\r\n",
        "    encoder = self.en_ldo(x)\r\n",
        "    \r\n",
        "    # 2.3.6 Decoder part\r\n",
        "    y = self.de_ld1(encoder)\r\n",
        "    y = self.de_ld2(y)\r\n",
        "    decoder = self.de_ld3(y)\r\n",
        "    return decoder\r\n",
        "\r\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgh2xDNZUDaX"
      },
      "source": [
        "# 2.4 Instantiate Autoencoder\r\n",
        "autoencoder  = Autoencoder(100, 0.1)\r\n",
        "# 2.4.1 Input layer\r\n",
        "inputs = layers.Input(shape = x_train.shape[1])\r\n",
        "# 2.4.2 Create model\r\n",
        "out_decoder = autoencoder(inputs)            \r\n",
        "model = Model(inputs = inputs, outputs = out_decoder)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8wsG_dVf-mR",
        "outputId": "08c9bdd5-e7a4-4c42-8391-9f15780f89be"
      },
      "source": [
        "# 2.5 Summaries of two models/classes\r\n",
        "print(\"Model summary\")\r\n",
        "print(\"=============\")\r\n",
        "\r\n",
        "# 2.5.1\r\n",
        "model.summary()\r\n",
        "print(\"\\n\\nAutoencoder summary--Full details of inner layers\")\r\n",
        "print(\"==================================================\")\r\n",
        "\r\n",
        "autoencoder.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary\n",
            "=============\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "autoencoder_24 (Autoencoder) (None, 784)               198084    \n",
            "=================================================================\n",
            "Total params: 198,084\n",
            "Trainable params: 198,084\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Autoencoder summary--Full details of inner layers\n",
            "==================================================\n",
            "Model: \"autoencoder_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_146 (Dense)            multiple                  78500     \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            multiple                  10100     \n",
            "_________________________________________________________________\n",
            "gaussian_noise_17 (GaussianN multiple                  0         \n",
            "_________________________________________________________________\n",
            "encoder (Dense)              multiple                  10100     \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            multiple                  10100     \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            multiple                  10100     \n",
            "_________________________________________________________________\n",
            "decoder (Dense)              multiple                  79184     \n",
            "=================================================================\n",
            "Total params: 198,084\n",
            "Trainable params: 198,084\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "-cR9r7xCm_7W",
        "outputId": "cba2168a-4d6e-4e2b-a9a8-64b8bb895be6"
      },
      "source": [
        "# 2.5.2\r\n",
        "print(\"Main Model plot\")\r\n",
        "plot_model(model)\r\n",
        "# Printing autoencoder plot\r\n",
        "# does not show inner layers\r\n",
        "print(\"\\n\\nAutoencoder plot--No inner layers seen\\n\")\r\n",
        "plot_model(autoencoder)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Main Model plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Autoencoder plot--No inner layers seen\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJwAAAA8CAIAAAAcxkT0AAAABmJLR0QA/wD/AP+gvaeTAAAHoElEQVR4nO2ca0gU3xuA31l1Z/bmZVWydL3kWiYaVAYVBklE9CUyNQQ/BZKkpZGp4IqEkaVbKniBNOmDgpmLGBRkpHSRxIoubpqWgteS9bbu6qyXdH4fhoZRV91d/Vv/w3m+zXvOvO/LeXbm7J1gGAYwaCH42w1gNh8sFUGwVATBUhHEnn/Q0tKSn5//t1rB2MzVq1cPHz7MHS65UgcGBjQazZa3hNkQGo1mYGCAH7FfOam2tnar+sFsAgRBLIvgPRVBsFQEwVIRBEtFECwVQbBUBMFSEQRLRRAsFUGwVATBUhEES0UQLBVBsFQEwVKXEBcXJ5PJCIL4/Pnz5mbOzs4OCgpydHQkSVKpVKalpU1NTZmdOTMzExgYmJmZaXMtLHUJ9+/fLy8v/19kbmpqunTpUm9v7+joaE5OTmFhYXR0tNmZKpWqq6trI7W2TqrJZDpy5MiWlfvXkEql8fHxcrlcJpOdO3cuIiLi2bNny76xAABv3779+vXrBmttndSKigqdTrdl5Wxm5RcJNoUnT57Y2dlxh25ubgBA0zR/jslkSk1NLSws3GAtW6S+efMmKCjIycmJoqiQkJCGhgYASEpKEgqFHh4e7JzExESJREIQxOjoKABcuXIlJSWlp6eHIAilUgkADMPk5+fv2bOHJEkXF5czZ850dnZyJRYWFrKysry9vUUi0d69e2tqagCgtLRUIpGIxeLHjx+fOnXK0dHRy8ururqa31tlZWVoaChFURKJxNfX98aNG+vWYhhGrVbv3r2bJEknJ6fU1FR+QrOd5OXlicVimUym0+lSUlI8PT2tvWEODQ2JRCI/Pz9+UKVSJSYmuru7W5XKDAwPtmNmPWpra69fvz4+Pj42Nnbo0CFXV1c2Hhsbu23bNm6aWq0GgJGREfYwMjLS39+fG83KyhIKhZWVlXq9vq2tbf/+/W5ubsPDw+zotWvXSJLUaDQTExMZGRkCgeD9+/cMw6hUKgBobGycnJzU6XRHjx6VSCRzc3PsWQUFBQBw69atsbGx8fHxe/fuxcbGrltLpVIRBHH37t2JiQmapktKSgDg06dPlnSSnJxcVFR09uzZb9++rbtuHNPT0zKZLCkpiR9sbm4+ffo0wzAjIyOsYAuzAUBNTc2SCP/AQql8cnJyAECn0zHWSKVpWiqVxsTEcJPfvXsHANnZ2QzDmEwmsVjMjdI0TZJkQkIC82cpTSYTO8QK6O7uZhhmbm7O2dk5PDycy/n79+/CwsK1a9E0LRaLT5w4wY2ylz4r1fJOrEKlUu3atctgMHARmqZDQ0MHBweZzZC60T3VwcEBABYWFqw6q729fWpqKjQ0lIscPHhQKBS2trYCQFdXF03TwcHB7JBIJPLw8ODfMDmEQiEAzM/PA0BbW5terz958iQ3amdnl5ycvHat7u5umqaPHz9utk/LO7Gcurq6R48eNTQ0yGQyLpiRkXHhwgVPT8+NZOawRerTp0+PHTvm7u5OkmRaWpoNGfR6PQBIpVJ+0NnZ2Wg0AsD09DQAZGZmEn/o6+tb9pxiJQaDgU1iVa3BwUEAWG0bs62TNXj48OHt27dfvnzp6+vLBZubm7VabVxcnM1pl2G11P7+/oiICA8Pj9bW1snJydzcXBuqskvPLiuHXq/38vKCP0tcUFDAv6W0tLSsnXPHjh0AwD4vs7wWRVEAMDs7azanbZ2sRlFRUVVVVVNTE9sqR0VFRWNjo0AgYB83bNGbN28SBPHhwwcbClktVavVzs/PJyQk7Ny5k6Io/gsAe3t79k64LsHBwVKplN9xa2vr3NzcgQMHAEChUFAUZe17Or6+vnK5/Pnz51bVCg4OFggEr169MpvTtk5WwjBMenq6Vqutr69fds8AgAcPHvAfNPw9lb9rWI7VUr29vQHgxYsXMzMzP378YHcmFqVSOT4+Xl9fPz8/PzIy0tfXxz9RLpf//Pmzt7fXaDTa2dmlpKTU1dVVVVUZDAatVnvx4sXt27fHx8cDAEVR58+fr66uLi0tNRgMCwsLg4ODv379WrsxkiQzMjJev36dlJQ0NDS0uLhoNBo7Ojooilqjlru7e2RkpEajqaioMBgMbW1tZWVlXE7bOllJR0dHXl5eeXm5g4MDwePOnTvWprII/mPEwme/6enpcrnc2dk5Ojq6uLgYAPz9/fv7+8fGxsLDwymK8vPzu3z5MvuCT6lU9vf3Mwzz8eNHHx8fkUgUFhY2PDy8uLioVqsDAgIcHBxcXFwiIiK6urq4ErOzs+np6d7e3vb29uy6t7e3l5SUiMViAAgICOjp6SkrK3N0dAQAHx+f79+/sycWFxeHhIRQFEVR1L59+0pKShiGWbuW0WiMi4tzdXWVSqVhYWFZWVkA4OXl9eXLl9U6yc3NFYlEAKBQKCorK9ddMa1Wa3bx1Wr1ysl//yUN5q+zUip+Qx9BsNRNoLOzk1idmJiYLe7HzE8ZMdYSGBjI/Et/coOvVATBUhEES0UQLBVBsFQEwVIRBEtFECwVQbBUBMFSEQRLRRAsFUGwVATBUhHEzEdvq/0aC/P/wpIrVaFQREVF/a1WMLYRFRWlUCj4EeKf+nQXsyngPRVBsFQEwVIRBEtFkP8AMlLcVNpb38YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVI1uxltfQzP",
        "outputId": "9fbb67b6-ba32-4b1f-dd76-db08b82d3ada"
      },
      "source": [
        "# 3.0 Instantiate, compile and train autoencoder\r\n",
        "model.compile(optimizer='adam', loss=\"mse\")\r\n",
        "model.fit(x_train, x_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test)\r\n",
        "                )\r\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0386 - val_loss: 0.0175\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0167 - val_loss: 0.0146\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0144 - val_loss: 0.0133\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0130 - val_loss: 0.0123\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0122 - val_loss: 0.0117\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0116 - val_loss: 0.0111\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0111 - val_loss: 0.0108\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0108 - val_loss: 0.0107\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0105 - val_loss: 0.0101\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0102 - val_loss: 0.0100\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0099 - val_loss: 0.0099\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0097 - val_loss: 0.0098\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0096 - val_loss: 0.0095\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0094 - val_loss: 0.0095\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0092 - val_loss: 0.0095\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0091 - val_loss: 0.0091\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0091 - val_loss: 0.0090\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0090 - val_loss: 0.0090\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0089 - val_loss: 0.0089\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0088 - val_loss: 0.0088\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0088 - val_loss: 0.0088\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0087 - val_loss: 0.0087\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0086 - val_loss: 0.0086\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0086 - val_loss: 0.0087\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0085 - val_loss: 0.0087\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - val_loss: 0.0084\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - val_loss: 0.0084\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - val_loss: 0.0088\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - val_loss: 0.0085\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - val_loss: 0.0085\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0083 - val_loss: 0.0083\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0083 - val_loss: 0.0083\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0081 - val_loss: 0.0080\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0081 - val_loss: 0.0082\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0081 - val_loss: 0.0082\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0080 - val_loss: 0.0082\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0080 - val_loss: 0.0083\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0080 - val_loss: 0.0081\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - val_loss: 0.0082\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0079 - val_loss: 0.0081\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0079 - val_loss: 0.0081\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0079 - val_loss: 0.0081\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - val_loss: 0.0079\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0079 - val_loss: 0.0079\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0078 - val_loss: 0.0080\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0080\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0077 - val_loss: 0.0080\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0079\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - val_loss: 0.0078\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0076\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0076 - val_loss: 0.0076\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0078\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0075 - val_loss: 0.0076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1e197a5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgTclMTsdd1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "7b94acaa-0394-4e41-a91e-e5e94206fd41"
      },
      "source": [
        "# 3.2 Just look at autoencoder layers\r\n",
        "#     and their names\r\n",
        "autoencoder.layers\r\n",
        "print(\"\\n\\nNamed Autoencoder Layers:\")\r\n",
        "print(\"==================\")\r\n",
        "for layer in autoencoder.layers:\r\n",
        "    print (layer.name)\r\n",
        "\r\n",
        "print(\"\\n\\nName of 3rd autoencoder layer:\")\r\n",
        "print(\"===========================\")\r\n",
        "autoencoder.layers[3].name"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7fb1e8855dd8>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fb1e87e9470>,\n",
              " <tensorflow.python.keras.layers.noise.GaussianNoise at 0x7fb1e87e9748>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fb1e8456c88>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fb1e8a9a358>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fb1e842b748>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fb1e84eae80>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Named Autoencoder Layers:\n",
            "==================\n",
            "dense_146\n",
            "dense_147\n",
            "gaussian_noise_17\n",
            "encoder\n",
            "dense_148\n",
            "dense_149\n",
            "decoder\n",
            "\n",
            "\n",
            "Name of 3rd autoencoder layer:\n",
            "===========================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'encoder'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu4uMR9IU4vf"
      },
      "source": [
        "# 4.0 Design an Autoencoder with Subclassing\r\n",
        "#     BUT Encoder has NO noise added\r\n",
        "\r\n",
        "latent_dim = 64 \r\n",
        "class Autoencoder_n(Model):\r\n",
        "\r\n",
        "  # 4.1 Design all layers\r\n",
        "  def __init__(self, latent_dim):\r\n",
        "    super(Autoencoder_n, self).__init__()\r\n",
        "    self.latent_dim = latent_dim\r\n",
        "    \r\n",
        "    # 4.2 Define layers. \r\n",
        "    #layers.Input(shape=(784,)),\r\n",
        "    self.en_ld1 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.en_ld2 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    #self.en_lg  = layers.GaussianNoise(0.1)   # Add some noise\r\n",
        "    self.en_ldo = layers.Dense(self.latent_dim, activation='relu', name = \"encoder\")\r\n",
        "\r\n",
        "    # 4.3 This is our decoder\r\n",
        "    self.de_ld1 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.de_ld2 = layers.Dense(self.latent_dim, activation='relu')\r\n",
        "    self.de_ld3 = layers.Dense(784, activation='sigmoid',name = \"decoder\")\r\n",
        "    #layers.Reshape((28, 28))\r\n",
        "\r\n",
        "  \r\n",
        "  # 4.4 Call function with just one parameter    \r\n",
        "  def call(self, inputs):\r\n",
        "    x = self.en_ld1(inputs)\r\n",
        "    x = self.en_ld2(x)\r\n",
        "    #x = self.en_lg(x)\r\n",
        "    encoder = self.en_ldo(x)\r\n",
        "\r\n",
        "    y = self.de_ld1(encoder)\r\n",
        "    y = self.de_ld2(y)\r\n",
        "    decoder = self.de_ld3(y)\r\n",
        "    return decoder"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFcbBWjVQGT",
        "outputId": "edec81b7-7e36-40a5-9751-6f204f88ef2a"
      },
      "source": [
        "# 5.0 As our model has been built using subclassing API,\r\n",
        "#     to intantiate the model, we have to fit it.\r\n",
        "#     Of course, this training is of no use as we will\r\n",
        "#     soon replace the encoder weights by the learned weights\r\n",
        "#     of earlier autoencoder\r\n",
        "\r\n",
        "autoencoder_n = Autoencoder_n(100)\r\n",
        "autoencoder_n.compile(optimizer='adam', loss=\"mse\")\r\n",
        "autoencoder_n.fit(x_train, x_train,\r\n",
        "                epochs= 3,      # No need to increase it\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, x_test))\r\n",
        "\r\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0381 - val_loss: 0.0173\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0162 - val_loss: 0.0140\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0137 - val_loss: 0.0128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1e8604ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "L02jfyuFuOxP",
        "outputId": "e2613028-b917-4557-be65-87b6ccd161aa"
      },
      "source": [
        "# 5.1 Names of layers in autoencoder_n\r\n",
        "for layer in autoencoder_n.layers:\r\n",
        "  print(layer.name)\r\n",
        "\r\n",
        "# 5.2 And 'encoder' layer  \r\n",
        "print(\"\\n\")\r\n",
        "autoencoder_n.layers[2].name  "
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_150\n",
            "dense_151\n",
            "encoder\n",
            "dense_152\n",
            "dense_153\n",
            "decoder\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'encoder'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puk2TK9Zukuk",
        "outputId": "46093af6-a699-48d9-93b4-233c321dec5a"
      },
      "source": [
        "# 5.3 Just experimenting\r\n",
        "autoencoder.layers[4].get_weights()[0].shape\r\n",
        "autoencoder.layers[3].get_weights()[0].shape\r\n",
        "autoencoder.layers[1].get_weights()[0].shape\r\n",
        "autoencoder.layers[0].get_weights()[0].shape\r\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMkLkswaWxY2"
      },
      "source": [
        "# 5.4 Replace 'encoder' weights of autoencoder_n\r\n",
        "#     with those in trained autoencoder\r\n",
        "#     Note that autoencoder.layers[2] is GaussianNoise layer\r\n",
        "\r\n",
        "autoencoder_n.layers[0].set_weights(autoencoder.layers[0].get_weights())\r\n",
        "autoencoder_n.layers[1].set_weights(autoencoder.layers[1].get_weights())\r\n",
        "# autoencoder_n.layers[2].set_weights(autoencoder.layers[2].get_weights())\r\n",
        "autoencoder_n.layers[2].set_weights(autoencoder.layers[3].get_weights())\r\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8eSAC0NfQ6i"
      },
      "source": [
        "# 6.0 So now we have two autoencoders. One which was trained with noise added\r\n",
        "#     to input. And the other whose 'encoder' has the same weights as of earlier\r\n",
        "#     autoencoder. BUT this autoencoder does NOT have, so-to-say GaussianNoise layer."
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEGs9nThiPr9"
      },
      "source": [
        "# Classification\r\n",
        "Using autoencoder pre-trained weights while performing classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmrPvHKY8455"
      },
      "source": [
        "# 7.0 Define our Classification model\r\n",
        "#     We use pretrained layers of autoencoder\r\n",
        "def class_model(trainable = False):\r\n",
        "  # 7.1\r\n",
        "  inputs = layers.Input(shape = x_train.shape[1:])\r\n",
        "  # 7.2 Encoder part of autoencoder\r\n",
        "  x = autoencoder_n.layers[0](inputs)\r\n",
        "  x = autoencoder_n.layers[1](x)\r\n",
        "  x = autoencoder_n.layers[2](x)\r\n",
        "  # 7.3 Output layer\r\n",
        "  x = layers.Dense(10,activation = \"softmax\")(x)\r\n",
        "  # 7.4 Our model\r\n",
        "  model1 = Model(inputs = [inputs], outputs = [x])\r\n",
        "  # 7.5 Should encoder be trainable or not?\r\n",
        "  for layer in range(4):\r\n",
        "    model1.layers[layer].trainable = trainable\r\n",
        "  return model1  \r\n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJyB92zeJVL2",
        "outputId": "52d1e60d-2563-466d-91fe-73d5e85a6684"
      },
      "source": [
        "# 8.0 Instantiate classification model and train it\r\n",
        "#     Encoder weights will not be 'trained/changed'\r\n",
        "model1 = class_model(False)\r\n",
        "# 8.1\r\n",
        "model1.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "# 8.2\r\n",
        "model1.fit(x_train, y_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, y_test)\r\n",
        "                )"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3633 - accuracy: 0.5828 - val_loss: 0.5181 - val_accuracy: 0.8196\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4873 - accuracy: 0.8277 - val_loss: 0.4933 - val_accuracy: 0.8236\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4498 - accuracy: 0.8411 - val_loss: 0.4917 - val_accuracy: 0.8256\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4440 - accuracy: 0.8433 - val_loss: 0.4891 - val_accuracy: 0.8346\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4368 - accuracy: 0.8481 - val_loss: 0.4704 - val_accuracy: 0.8353\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4409 - accuracy: 0.8472 - val_loss: 0.4799 - val_accuracy: 0.8361\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4348 - accuracy: 0.8488 - val_loss: 0.4725 - val_accuracy: 0.8357\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4306 - accuracy: 0.8513 - val_loss: 0.4798 - val_accuracy: 0.8316\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4320 - accuracy: 0.8506 - val_loss: 0.4667 - val_accuracy: 0.8420\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4328 - accuracy: 0.8504 - val_loss: 0.4701 - val_accuracy: 0.8410\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4353 - accuracy: 0.8504 - val_loss: 0.4790 - val_accuracy: 0.8350\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4337 - accuracy: 0.8512 - val_loss: 0.4834 - val_accuracy: 0.8304\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4336 - accuracy: 0.8508 - val_loss: 0.4723 - val_accuracy: 0.8397\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4312 - accuracy: 0.8517 - val_loss: 0.4697 - val_accuracy: 0.8415\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4380 - accuracy: 0.8521 - val_loss: 0.4843 - val_accuracy: 0.8349\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4357 - accuracy: 0.8503 - val_loss: 0.4745 - val_accuracy: 0.8375\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4381 - accuracy: 0.8512 - val_loss: 0.4781 - val_accuracy: 0.8403\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4339 - accuracy: 0.8528 - val_loss: 0.4814 - val_accuracy: 0.8386\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4334 - accuracy: 0.8551 - val_loss: 0.4695 - val_accuracy: 0.8435\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4364 - accuracy: 0.8499 - val_loss: 0.4784 - val_accuracy: 0.8386\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4237 - accuracy: 0.8541 - val_loss: 0.4840 - val_accuracy: 0.8324\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4352 - accuracy: 0.8506 - val_loss: 0.4811 - val_accuracy: 0.8384\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4347 - accuracy: 0.8544 - val_loss: 0.4807 - val_accuracy: 0.8410\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4216 - accuracy: 0.8553 - val_loss: 0.4725 - val_accuracy: 0.8404\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4386 - accuracy: 0.8532 - val_loss: 0.4769 - val_accuracy: 0.8412\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4434 - accuracy: 0.8513 - val_loss: 0.4838 - val_accuracy: 0.8387\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4226 - accuracy: 0.8569 - val_loss: 0.4848 - val_accuracy: 0.8390\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4312 - accuracy: 0.8547 - val_loss: 0.4844 - val_accuracy: 0.8359\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4353 - accuracy: 0.8552 - val_loss: 0.4815 - val_accuracy: 0.8410\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4401 - accuracy: 0.8528 - val_loss: 0.4767 - val_accuracy: 0.8404\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4307 - accuracy: 0.8541 - val_loss: 0.4933 - val_accuracy: 0.8340\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.8531 - val_loss: 0.4879 - val_accuracy: 0.8367\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4388 - accuracy: 0.8529 - val_loss: 0.4776 - val_accuracy: 0.8410\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4318 - accuracy: 0.8562 - val_loss: 0.4821 - val_accuracy: 0.8380\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4423 - accuracy: 0.8507 - val_loss: 0.4826 - val_accuracy: 0.8424\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4324 - accuracy: 0.8550 - val_loss: 0.4849 - val_accuracy: 0.8390\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4419 - accuracy: 0.8517 - val_loss: 0.4802 - val_accuracy: 0.8416\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4397 - accuracy: 0.8512 - val_loss: 0.4776 - val_accuracy: 0.8428\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4367 - accuracy: 0.8523 - val_loss: 0.4748 - val_accuracy: 0.8458\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4377 - accuracy: 0.8521 - val_loss: 0.4836 - val_accuracy: 0.8402\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4297 - accuracy: 0.8579 - val_loss: 0.4797 - val_accuracy: 0.8437\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4400 - accuracy: 0.8526 - val_loss: 0.5061 - val_accuracy: 0.8313\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4394 - accuracy: 0.8538 - val_loss: 0.4832 - val_accuracy: 0.8415\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4381 - accuracy: 0.8538 - val_loss: 0.4925 - val_accuracy: 0.8404\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4316 - accuracy: 0.8539 - val_loss: 0.4987 - val_accuracy: 0.8355\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4401 - accuracy: 0.8529 - val_loss: 0.4826 - val_accuracy: 0.8414\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4405 - accuracy: 0.8534 - val_loss: 0.5036 - val_accuracy: 0.8366\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4381 - accuracy: 0.8534 - val_loss: 0.4837 - val_accuracy: 0.8422\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4426 - accuracy: 0.8538 - val_loss: 0.4802 - val_accuracy: 0.8434\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4379 - accuracy: 0.8530 - val_loss: 0.4834 - val_accuracy: 0.8416\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4455 - accuracy: 0.8533 - val_loss: 0.4814 - val_accuracy: 0.8426\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4381 - accuracy: 0.8568 - val_loss: 0.4818 - val_accuracy: 0.8434\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4454 - accuracy: 0.8519 - val_loss: 0.4943 - val_accuracy: 0.8365\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4431 - accuracy: 0.8523 - val_loss: 0.4959 - val_accuracy: 0.8428\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4418 - accuracy: 0.8534 - val_loss: 0.4835 - val_accuracy: 0.8402\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4443 - accuracy: 0.8530 - val_loss: 0.4910 - val_accuracy: 0.8399\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4480 - accuracy: 0.8515 - val_loss: 0.4856 - val_accuracy: 0.8435\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4395 - accuracy: 0.8544 - val_loss: 0.4976 - val_accuracy: 0.8344\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4317 - accuracy: 0.8576 - val_loss: 0.4919 - val_accuracy: 0.8409\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4375 - accuracy: 0.8532 - val_loss: 0.4970 - val_accuracy: 0.8334\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4474 - accuracy: 0.8503 - val_loss: 0.4975 - val_accuracy: 0.8365\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4340 - accuracy: 0.8545 - val_loss: 0.4927 - val_accuracy: 0.8399\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4456 - accuracy: 0.8542 - val_loss: 0.4833 - val_accuracy: 0.8425\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4451 - accuracy: 0.8536 - val_loss: 0.5014 - val_accuracy: 0.8335\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4403 - accuracy: 0.8531 - val_loss: 0.5032 - val_accuracy: 0.8369\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4371 - accuracy: 0.8557 - val_loss: 0.4910 - val_accuracy: 0.8414\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4437 - accuracy: 0.8533 - val_loss: 0.5131 - val_accuracy: 0.8362\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4452 - accuracy: 0.8530 - val_loss: 0.4839 - val_accuracy: 0.8433\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4464 - accuracy: 0.8524 - val_loss: 0.4921 - val_accuracy: 0.8397\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4382 - accuracy: 0.8547 - val_loss: 0.4983 - val_accuracy: 0.8390\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4425 - accuracy: 0.8540 - val_loss: 0.4966 - val_accuracy: 0.8398\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4401 - accuracy: 0.8556 - val_loss: 0.4940 - val_accuracy: 0.8395\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4492 - accuracy: 0.8545 - val_loss: 0.4927 - val_accuracy: 0.8412\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4442 - accuracy: 0.8559 - val_loss: 0.4949 - val_accuracy: 0.8424\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4509 - accuracy: 0.8516 - val_loss: 0.4974 - val_accuracy: 0.8402\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4428 - accuracy: 0.8519 - val_loss: 0.5115 - val_accuracy: 0.8368\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4412 - accuracy: 0.8558 - val_loss: 0.5009 - val_accuracy: 0.8397\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4360 - accuracy: 0.8567 - val_loss: 0.4986 - val_accuracy: 0.8382\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4443 - accuracy: 0.8523 - val_loss: 0.4926 - val_accuracy: 0.8410\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4384 - accuracy: 0.8564 - val_loss: 0.4976 - val_accuracy: 0.8404\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4453 - accuracy: 0.8539 - val_loss: 0.5054 - val_accuracy: 0.8383\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4468 - accuracy: 0.8517 - val_loss: 0.4991 - val_accuracy: 0.8376\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4408 - accuracy: 0.8539 - val_loss: 0.4883 - val_accuracy: 0.8407\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4419 - accuracy: 0.8555 - val_loss: 0.4888 - val_accuracy: 0.8453\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4457 - accuracy: 0.8508 - val_loss: 0.4927 - val_accuracy: 0.8429\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4339 - accuracy: 0.8561 - val_loss: 0.4942 - val_accuracy: 0.8409\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4468 - accuracy: 0.8546 - val_loss: 0.4954 - val_accuracy: 0.8433\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4425 - accuracy: 0.8536 - val_loss: 0.4912 - val_accuracy: 0.8423\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4440 - accuracy: 0.8556 - val_loss: 0.4990 - val_accuracy: 0.8386\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4531 - accuracy: 0.8522 - val_loss: 0.5111 - val_accuracy: 0.8369\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4423 - accuracy: 0.8538 - val_loss: 0.4985 - val_accuracy: 0.8424\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4389 - accuracy: 0.8540 - val_loss: 0.5174 - val_accuracy: 0.8364\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4445 - accuracy: 0.8516 - val_loss: 0.5087 - val_accuracy: 0.8296\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4531 - accuracy: 0.8525 - val_loss: 0.4912 - val_accuracy: 0.8419\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4483 - accuracy: 0.8534 - val_loss: 0.4965 - val_accuracy: 0.8389\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4519 - accuracy: 0.8541 - val_loss: 0.5004 - val_accuracy: 0.8414\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4473 - accuracy: 0.8536 - val_loss: 0.4971 - val_accuracy: 0.8403\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4440 - accuracy: 0.8528 - val_loss: 0.4984 - val_accuracy: 0.8390\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4489 - accuracy: 0.8542 - val_loss: 0.4978 - val_accuracy: 0.8421\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4539 - accuracy: 0.8555 - val_loss: 0.5156 - val_accuracy: 0.8381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1dff5f7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0_gpKiokzp9",
        "outputId": "f9a81561-3bb7-4bb5-b4f3-575a0c86b0cd"
      },
      "source": [
        "# 8.3 Evaluate model\r\n",
        "model1.evaluate(x_test, y_test)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.8381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5156015157699585, 0.838100016117096]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi0kq3elIpq9",
        "outputId": "d1b7d588-cc91-4689-9b7e-7ec590cf3c85"
      },
      "source": [
        "# 8.4 Also get its summary\r\n",
        "model1.summary()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "encoder (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 99,710\n",
            "Trainable params: 1,010\n",
            "Non-trainable params: 98,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mYAfU_zObRU",
        "outputId": "25ebbda0-854c-459c-bae2-93b101ded5a5"
      },
      "source": [
        "# 9.0 Run the classification model again but \r\n",
        "#     this time train the 'encoder' part of\r\n",
        "#     classification layer also\r\n",
        "\r\n",
        "model2 = class_model(True)\r\n",
        "# 9.1\r\n",
        "model2.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")\r\n",
        "# 9.2\r\n",
        "model2.fit(x_train, y_train,\r\n",
        "                epochs=100,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(x_test, y_test)\r\n",
        "                )"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6605 - accuracy: 0.7784 - val_loss: 0.4396 - val_accuracy: 0.8471\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3782 - accuracy: 0.8641 - val_loss: 0.4063 - val_accuracy: 0.8664\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3529 - accuracy: 0.8771 - val_loss: 0.4246 - val_accuracy: 0.8510\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3513 - accuracy: 0.8755 - val_loss: 0.4409 - val_accuracy: 0.8620\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3508 - accuracy: 0.8799 - val_loss: 0.4279 - val_accuracy: 0.8646\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3462 - accuracy: 0.8797 - val_loss: 0.4681 - val_accuracy: 0.8592\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3453 - accuracy: 0.8837 - val_loss: 0.4872 - val_accuracy: 0.8566\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3415 - accuracy: 0.8829 - val_loss: 0.5104 - val_accuracy: 0.8491\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3458 - accuracy: 0.8806 - val_loss: 0.4727 - val_accuracy: 0.8616\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3485 - accuracy: 0.8852 - val_loss: 0.4702 - val_accuracy: 0.8597\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3484 - accuracy: 0.8846 - val_loss: 0.4763 - val_accuracy: 0.8677\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3391 - accuracy: 0.8882 - val_loss: 0.5516 - val_accuracy: 0.8615\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3498 - accuracy: 0.8857 - val_loss: 0.5098 - val_accuracy: 0.8694\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3507 - accuracy: 0.8891 - val_loss: 0.5579 - val_accuracy: 0.8521\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3464 - accuracy: 0.8859 - val_loss: 0.6375 - val_accuracy: 0.8708\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3367 - accuracy: 0.8891 - val_loss: 0.6759 - val_accuracy: 0.8504\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3410 - accuracy: 0.8916 - val_loss: 0.6432 - val_accuracy: 0.8716\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3422 - accuracy: 0.8913 - val_loss: 0.6673 - val_accuracy: 0.8705\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3352 - accuracy: 0.8892 - val_loss: 0.8114 - val_accuracy: 0.8573\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3489 - accuracy: 0.8910 - val_loss: 0.6853 - val_accuracy: 0.8689\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3421 - accuracy: 0.8917 - val_loss: 0.7374 - val_accuracy: 0.8712\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3272 - accuracy: 0.8939 - val_loss: 0.7901 - val_accuracy: 0.8665\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3425 - accuracy: 0.8902 - val_loss: 0.8300 - val_accuracy: 0.8759\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3367 - accuracy: 0.8926 - val_loss: 0.8196 - val_accuracy: 0.8498\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3340 - accuracy: 0.8927 - val_loss: 0.7621 - val_accuracy: 0.8649\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3304 - accuracy: 0.8956 - val_loss: 0.8970 - val_accuracy: 0.8560\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3326 - accuracy: 0.8967 - val_loss: 0.7522 - val_accuracy: 0.8667\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3269 - accuracy: 0.8967 - val_loss: 0.8312 - val_accuracy: 0.8612\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3247 - accuracy: 0.8955 - val_loss: 0.7767 - val_accuracy: 0.8615\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3283 - accuracy: 0.8990 - val_loss: 1.2724 - val_accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3436 - accuracy: 0.8975 - val_loss: 0.8030 - val_accuracy: 0.8589\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3289 - accuracy: 0.8990 - val_loss: 0.8470 - val_accuracy: 0.8741\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3258 - accuracy: 0.8974 - val_loss: 0.9772 - val_accuracy: 0.8771\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3161 - accuracy: 0.8989 - val_loss: 1.0055 - val_accuracy: 0.8710\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3188 - accuracy: 0.8993 - val_loss: 1.4131 - val_accuracy: 0.8616\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3353 - accuracy: 0.8971 - val_loss: 1.3070 - val_accuracy: 0.8620\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3424 - accuracy: 0.8981 - val_loss: 1.2261 - val_accuracy: 0.8697\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3420 - accuracy: 0.9020 - val_loss: 1.0996 - val_accuracy: 0.8606\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3230 - accuracy: 0.9016 - val_loss: 0.8410 - val_accuracy: 0.8668\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3434 - accuracy: 0.9000 - val_loss: 1.1737 - val_accuracy: 0.8716\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3414 - accuracy: 0.8991 - val_loss: 1.3275 - val_accuracy: 0.8575\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3382 - accuracy: 0.8991 - val_loss: 1.0968 - val_accuracy: 0.8743\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3589 - accuracy: 0.8985 - val_loss: 1.1158 - val_accuracy: 0.8706\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3308 - accuracy: 0.9008 - val_loss: 1.0739 - val_accuracy: 0.8614\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3301 - accuracy: 0.9025 - val_loss: 1.3795 - val_accuracy: 0.8604\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3430 - accuracy: 0.9013 - val_loss: 1.0428 - val_accuracy: 0.8657\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3353 - accuracy: 0.9016 - val_loss: 1.1533 - val_accuracy: 0.8675\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3578 - accuracy: 0.9039 - val_loss: 1.3204 - val_accuracy: 0.8737\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3449 - accuracy: 0.9014 - val_loss: 1.4241 - val_accuracy: 0.8721\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3346 - accuracy: 0.9022 - val_loss: 1.2332 - val_accuracy: 0.8723\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3514 - accuracy: 0.9038 - val_loss: 1.4986 - val_accuracy: 0.8699\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3354 - accuracy: 0.9043 - val_loss: 1.3413 - val_accuracy: 0.8649\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3352 - accuracy: 0.9018 - val_loss: 1.6458 - val_accuracy: 0.8769\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3499 - accuracy: 0.9017 - val_loss: 1.6203 - val_accuracy: 0.8743\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3532 - accuracy: 0.9036 - val_loss: 1.4449 - val_accuracy: 0.8708\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3439 - accuracy: 0.9032 - val_loss: 1.6535 - val_accuracy: 0.8637\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3835 - accuracy: 0.9028 - val_loss: 1.3485 - val_accuracy: 0.8719\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3758 - accuracy: 0.9004 - val_loss: 1.9187 - val_accuracy: 0.8538\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3668 - accuracy: 0.9051 - val_loss: 1.8318 - val_accuracy: 0.8767\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3457 - accuracy: 0.9038 - val_loss: 1.6252 - val_accuracy: 0.8767\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3379 - accuracy: 0.9064 - val_loss: 1.7672 - val_accuracy: 0.8701\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3558 - accuracy: 0.9056 - val_loss: 1.6727 - val_accuracy: 0.8636\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3478 - accuracy: 0.9042 - val_loss: 1.7220 - val_accuracy: 0.8578\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3475 - accuracy: 0.9046 - val_loss: 1.9698 - val_accuracy: 0.8716\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3629 - accuracy: 0.9062 - val_loss: 1.8538 - val_accuracy: 0.8743\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3867 - accuracy: 0.9046 - val_loss: 1.7543 - val_accuracy: 0.8682\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3709 - accuracy: 0.9050 - val_loss: 2.1892 - val_accuracy: 0.8755\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3723 - accuracy: 0.9064 - val_loss: 1.6939 - val_accuracy: 0.8728\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3877 - accuracy: 0.9075 - val_loss: 2.4367 - val_accuracy: 0.8666\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3861 - accuracy: 0.9047 - val_loss: 1.9237 - val_accuracy: 0.8755\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3622 - accuracy: 0.9064 - val_loss: 2.2638 - val_accuracy: 0.8642\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4189 - accuracy: 0.9055 - val_loss: 2.9847 - val_accuracy: 0.8715\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3754 - accuracy: 0.9055 - val_loss: 2.4638 - val_accuracy: 0.8578\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3693 - accuracy: 0.9030 - val_loss: 2.1338 - val_accuracy: 0.8708\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3411 - accuracy: 0.9086 - val_loss: 2.1520 - val_accuracy: 0.8671\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3632 - accuracy: 0.9081 - val_loss: 2.5045 - val_accuracy: 0.8661\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4240 - accuracy: 0.9066 - val_loss: 2.9019 - val_accuracy: 0.8643\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3763 - accuracy: 0.9079 - val_loss: 2.9836 - val_accuracy: 0.8687\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3820 - accuracy: 0.9087 - val_loss: 2.1852 - val_accuracy: 0.8599\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3987 - accuracy: 0.9063 - val_loss: 2.4035 - val_accuracy: 0.8670\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3538 - accuracy: 0.9094 - val_loss: 2.5597 - val_accuracy: 0.8640\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3464 - accuracy: 0.9083 - val_loss: 2.8709 - val_accuracy: 0.8678\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3767 - accuracy: 0.9074 - val_loss: 3.0206 - val_accuracy: 0.8609\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3698 - accuracy: 0.9073 - val_loss: 2.2952 - val_accuracy: 0.8660\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3864 - accuracy: 0.9090 - val_loss: 2.7020 - val_accuracy: 0.8663\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3956 - accuracy: 0.9057 - val_loss: 3.5075 - val_accuracy: 0.8698\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3987 - accuracy: 0.9077 - val_loss: 2.9845 - val_accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3829 - accuracy: 0.9069 - val_loss: 3.1560 - val_accuracy: 0.8650\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3327 - accuracy: 0.9113 - val_loss: 3.4125 - val_accuracy: 0.8492\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3825 - accuracy: 0.9055 - val_loss: 3.3975 - val_accuracy: 0.8620\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3790 - accuracy: 0.9083 - val_loss: 3.6318 - val_accuracy: 0.8743\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3952 - accuracy: 0.9085 - val_loss: 3.9550 - val_accuracy: 0.8493\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4893 - accuracy: 0.9048 - val_loss: 4.2315 - val_accuracy: 0.8561\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3804 - accuracy: 0.9076 - val_loss: 4.0902 - val_accuracy: 0.8596\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3869 - accuracy: 0.9069 - val_loss: 4.3187 - val_accuracy: 0.8627\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4172 - accuracy: 0.9068 - val_loss: 3.5133 - val_accuracy: 0.8706\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4237 - accuracy: 0.9082 - val_loss: 3.6473 - val_accuracy: 0.8576\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4087 - accuracy: 0.9074 - val_loss: 3.9701 - val_accuracy: 0.8563\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4729 - accuracy: 0.9076 - val_loss: 3.8488 - val_accuracy: 0.8632\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4028 - accuracy: 0.9086 - val_loss: 3.0304 - val_accuracy: 0.8465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1e88be358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NIL4F3OgCq",
        "outputId": "444a0af1-78b2-4291-9b78-d8fea4678793"
      },
      "source": [
        "# 9.3 Evaluate the model\r\n",
        "#    Observe that a pre-trained model using\r\n",
        "#    autoencoder gives better classification\r\n",
        "model2.evaluate(x_test,y_test)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 3.0304 - accuracy: 0.8465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.03037166595459, 0.8464999794960022]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSt7xaHkjduo",
        "outputId": "ac40ce33-2bba-4c79-e891-0491dc2ee228"
      },
      "source": [
        "# 10.0 If you evaluate model1 again, we get very low accuracy\r\n",
        "#     as autoencoder weights have changed\r\n",
        "model1.evaluate(x_test,y_test)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 154.6052 - accuracy: 0.1952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[154.60516357421875, 0.19519999623298645]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ91niuYxFM1"
      },
      "source": [
        "########## I am done ##########"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}