{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xR667_io78U-0K9VOa99nsQPUkh_VU2s",
      "authorship_tag": "ABX9TyOQrI+bsnQuDCfljnGOvStf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning/blob/main/cats_dogs_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJC_AYp9aX3j"
      },
      "source": [
        "# Last amended: 17th Feb, 2021\r\n",
        "# My folder: E:/cats_and_dogs/data\r\n",
        "# \r\n",
        "# Data folder:  '/home/ashok/Images/cats_dogs/\r\n",
        "# VM: lubuntu_deeplearning_I\r\n",
        "# Objectives:\r\n",
        "#           i)  Building powerful image classification models using\r\n",
        "#               very little data\r\n",
        "#           ii) Predicting cats and dogs--Kaggle\r\n",
        "#               https://www.kaggle.com/c/dogs-vs-cats\r\n",
        "#          iii) Calcualting model weights, stage-by-stage\r\n",
        "#"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAVggrYaaj3M"
      },
      "source": [
        "'''\r\n",
        "\r\n",
        "A. Arrange your data first\r\n",
        "==========================\r\n",
        "\r\n",
        "    Download data from: https://www.kaggle.com/c/dogs-vs-cats/data .\r\n",
        "    Unzip train.zip and arrange its files as follows:\r\n",
        "        data/\r\n",
        "            train/\r\n",
        "                dogs/                      1000\r\n",
        "                    dog001.jpg\r\n",
        "                    dog002.jpg\r\n",
        "                    ...\r\n",
        "                    dog1000.jpg\r\n",
        "                cats/                      1000\r\n",
        "                    cat001.jpg\r\n",
        "                    cat002.jpg\r\n",
        "                    ...\r\n",
        "                    cat1000.jpg\r\n",
        "           validation/\r\n",
        "               dogs/                        400\r\n",
        "                   dog1001.jpg\r\n",
        "                   dog1002.jpg\r\n",
        "                   ...\r\n",
        "                   dog1400.jpg\r\n",
        "              cats/                         400\r\n",
        "                  cat1001.jpg\r\n",
        "                  cat1002.jpg\r\n",
        "                  ...\r\n",
        "                  cat1004.jpg\r\n",
        "\r\n",
        "    So we are picking up only 1000 files of each category for training.\r\n",
        "    Arrangement of (only) 'training' files in this fashion has an advantage that\r\n",
        "    keras automatically knows which images are of cats and which images are\r\n",
        "    of dogs. It does automatic labeling of images; we do not have to specify\r\n",
        "    explicitly in the code for building training model. This automatic labelling\r\n",
        "    is done by ImageGenerator.\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LmCNdCQanAf"
      },
      "source": [
        "\"\"\"\r\n",
        "B. Training steps are as follows:\r\n",
        "=================================\r\n",
        "\r\n",
        "    1. Arrange training files as above. (Our total samples: nb_train_samples = 2000)\r\n",
        "    2. Arrange validation files as above (Valid Samples: nb_validation_samples = 800)\r\n",
        "    3. Specify location of all train folder and vaidation folder\r\n",
        "    4. Depending upon your backend (tensorflow/theano) decide\r\n",
        "       the shape/format of your input image arrays. This is needed in CNN modeling.\r\n",
        "    5. Build the CNN model & compile it\r\n",
        "\r\n",
        "    6. Use ImageDataGenerator to augment train images. This is in two steps:\r\n",
        "        i)  Create an object with configuration of possible changes in any image\r\n",
        "        ii) Use the object to create an iterator with following further configuration:\r\n",
        "                a)  Create iterator using flow(), '.flow_from_directory()' method\r\n",
        "            In '.flow_from_directory()', specify:\r\n",
        "                b)   Where is the directory of your images?\r\n",
        "            In ''.flow()' specify X_train, y_train\r\n",
        "            Further in both cases:\r\n",
        "                b)  Do you also want to resize images, if so, specify these\r\n",
        "                c) What batch-size to augment and model at a time;depends upon RAM\r\n",
        "                d)  Is classification binary or categorical?\r\n",
        "\r\n",
        "    7. Use ImageDataGenerator to augment validation images. Again the two steps\r\n",
        "       as above. But we only resize validation images.\r\n",
        "    8. Begin extracting images or training using the iterator fit_generator():\r\n",
        "        CNN fit_generator() takes these arguments:\r\n",
        "        i)   train-data-iterator (batch-wise source of train images)\r\n",
        "        ii)  validation-data generator (batch-wise source of validation images)\r\n",
        "        iii) no of epochs\r\n",
        "\r\n",
        "\r\n",
        "   9. After training has finished, save model weights to a '.h5' file and also\r\n",
        "      save model configuration to a json file.\r\n",
        "\r\n",
        "\r\n",
        "   ------------\r\n",
        "   Later, maybe, after some time\r\n",
        "   10.Unzip test data file in a folder (within another folder. This is impt.).\r\n",
        "   11.Configure test Image Data Generator\r\n",
        "   12.Use above configuration and test-folder address, to create a test generator\r\n",
        "   13.Load saved cnn model and load network weights in this model from saved h5 file\r\n",
        "   14.Use predict() to make predictions on test_generator.\r\n",
        "   15.Evaluate predictions\r\n",
        "\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SSBx6Craxcm"
      },
      "source": [
        "\"\"\"\r\n",
        "C. About keras backend:\r\n",
        "=======================\r\n",
        "\r\n",
        "    The default keras configuration file is in folder:\r\n",
        "        C:\\Users\\ashokharnal\\.keras.  It looks like as below.\r\n",
        "        The configurtion is as per the installed backend on your machine:\r\n",
        "        tensorflow, theano or CNTK\r\n",
        "\r\n",
        "            {\r\n",
        "                    \"image_data_format\": \"channels_last\",\r\n",
        "                    \"epsilon\": 1e-07,\r\n",
        "                    \"floatx\": \"float32\",\r\n",
        "                    \"backend\": \"tensorflow\"\r\n",
        "                    }\r\n",
        "\r\n",
        "            \"epsilon\" is used instead of zero when division is by zero. 'floatx'\r\n",
        "            specifies the datatype that keras will process.\r\n",
        "            For 2D data (e.g. image), \"channels_last\" assumes (rows,cols,channels)\r\n",
        "            while \"channels_first\" assumes (channels,rows,cols)\r\n",
        "            (channels stand for RGB colour channels)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ipEiLYya4Mc"
      },
      "source": [
        "\"\"\"\r\n",
        "D. Prerequisites:\r\n",
        "=================\r\n",
        "    Before attempting this problem, pl study Image Augmentation in Moodle at\r\n",
        "    http://203.122.28.230/moodle/course/view.php?id=11&sectionid=166#section-9\r\n",
        "\r\n",
        "E. Note\r\n",
        "=======\r\n",
        "    This is a full code from building model to making predictions for test data.\r\n",
        "    AUC is very less as no. of training epochs are just 5. The training consumes\r\n",
        "    time but very less memory (around 50%) on an 8GB machine. Vary batch size\r\n",
        "    to control memory usage.\r\n",
        "\r\n",
        "\r\n",
        "F. Make theano as backend\r\n",
        "=========================\r\n",
        "\r\n",
        "#    cp /home/ashok/.keras/keras_theano.json  /home/ashok/.keras/keras.json\r\n",
        "#    cat /home/ashok/.keras/keras.json\r\n",
        "#    source deactivate tensorflow\r\n",
        "#    source activate theano\r\n",
        "#    ipython\r\n",
        "\tIn file:  ~/.keras/keras.json, set:\r\n",
        "\r\n",
        "\t\"backend\": \"theano\",    # instead of \"tensorflow\"\r\n",
        "\r\n",
        "         Also the following environment variable needs to be set in bashrc:\r\n",
        "\r\n",
        "\t export \"MKL_THREADING_LAYER=GNU\"\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDXJaRnna-0n"
      },
      "source": [
        "\"\"\"\r\n",
        "\r\n",
        "TODO: Use livelossplot\r\n",
        "GitHub: https://github.com/stared/livelossplot\r\n",
        "SEE example:\r\n",
        "https://colab.research.google.com/github/stared/livelossplot/blob/master/examples/keras.ipynb\r\n",
        "\r\n",
        "\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5mbKmkPbFOJ"
      },
      "source": [
        "\r\n",
        "#%%                                A. Call libraries\r\n",
        "\r\n",
        "#        $ source activate theano\r\n",
        "#        $ ipython\r\n",
        "# OR in Windows\r\n",
        "#       > conda activate tensorflow_env\r\n",
        "#       > atom\r\n",
        "\r\n",
        "# 0. Release memory\r\n",
        "%reset -f\r\n",
        "\r\n",
        "# 1.0 Data manipulation library\r\n",
        "#     Install in 'tf' environment\r\n",
        "#     conda install -c anaconda pandas\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# 1.1 Call libraries for image processing\r\n",
        "#     Another preprocessing option is text and sequence\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "# 1.2, Libraries for building sequential CNN model\r\n",
        "#      A model is composed of sequence of layered objects\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\r\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\r\n",
        "\r\n",
        "# 1.3.Keras has three backend implementations available: the TensorFlow,\r\n",
        "#    the Theano, and CNTK backend.\r\n",
        "\"\"\"\r\n",
        "What is a \"backend\"?\r\n",
        "(http://faroit.com/keras-docs/1.2.0/backend/)\r\n",
        "    Keras is a model-level library, providing high-level building blocks\r\n",
        "    for developing deep learning models. It does not handle itself low-level\r\n",
        "    operations such as tensor products, convolutions and so on. Instead,\r\n",
        "    it relies on a specialized, well-optimized tensor manipulation library\r\n",
        "    to do so, serving as the \"backend engine\" of Keras.\r\n",
        "    List of low-level functions:\r\n",
        "    https://www.tensorflow.org/api_docs/python/tf/keras/backend\r\n",
        "\"\"\"\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "# 1.4 Save CNN model configuration\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "\r\n",
        "# 1.5 OS related\r\n",
        "import os\r\n",
        "\r\n",
        "# 1.6 For ROC plotting\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# 1.7\r\n",
        "import numpy as np\r\n",
        "# conda install scikit-learn\r\n",
        "from sklearn import metrics\r\n",
        "import time\r\n",
        "#from skimage import exposure           # Not used\r\n",
        "\r\n",
        "# 1.8\r\n",
        "# conda install -c anaconda pillow\r\n",
        "#  Then deactivate and activate environment\r\n",
        "#   This step is a must here\r\n",
        "from PIL import Image                  # Needed in Windows\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moDpeFO5HOhl"
      },
      "source": [
        "# Make two folders, one for .tar.gz file\r\n",
        "#  and the other for unzipped files\r\n",
        "! mkdir /root/catsdogs\r\n",
        "! mkdir /root/ashok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5eq76HPHBPq"
      },
      "source": [
        "# Copy tar.gz file from Google drive to Virtual machine\r\n",
        "! cp /content/drive/MyDrive/Colab_data_files/cats_dogs.tar.gz  /root/catsdogs\r\n",
        "# And check\r\n",
        "! ls /root/catsdogs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bwvTgdOH1Tn"
      },
      "source": [
        "# Untar file to folder /root/ashok/\r\n",
        "! tar -xvf /root/catsdogs/cats_dogs.tar.gz  -C /root/ashok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzVXupejIcGu",
        "outputId": "2dacf715-c601-48ce-b5f6-8bee7db98b85"
      },
      "source": [
        "# Check folders under 'ashok'\r\n",
        "# Folder 'cats_dogs' should exist\r\n",
        "! ls /root/ashok/"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats  dogs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwjzEiBBbMTZ"
      },
      "source": [
        "#%%                            B. Define constants\r\n",
        "\r\n",
        "# 2. Our constants\r\n",
        "# 2.1 Dimensions to which our images will be adjusted\r\n",
        "img_width, img_height = 150, 150\r\n",
        "\r\n",
        "# 2.2 Data folder containing all training images, maybe in folders: cats and dogs\r\n",
        "#train_data_dir = '/home/ashok/Images/cats_dogs/train'\r\n",
        "#train_data_dir =\"C:\\\\Users\\\\ashok\\\\Desktop\\\\chmod\\\\2. data_augmentation\\\\cats_dogs\\\\train\"\r\n",
        "train_data_dir = '/root/ashok/cats_dogs/train'\r\n",
        "\r\n",
        "# 2.3 What is the total number of training images\r\n",
        "#      that should be generated (not what are available)\r\n",
        "nb_train_samples = 2000   # Actual: 1000 + 1000 (more) =    2000\r\n",
        "\r\n",
        "# 2.4 Data folder containing all validation images\r\n",
        "\r\n",
        "#validation_data_dir = '/home/ashok/Images/cats_dogs/validation'\r\n",
        "#validation_data_dir = \"C:\\\\Users\\\\ashok\\\\Desktop\\\\chmod\\\\2. data_augmentation\\\\cats_dogs\\\\validation\"\r\n",
        "validation_data_dir = '/root/ashok/cats_dogs/validation'\r\n",
        "\r\n",
        "# 2.5 What is the total no of validation samples that should\r\n",
        "#     be generated?\r\n",
        "nb_validation_samples = 800   # Actual: 400 + 400 (more) =  800\r\n",
        "\r\n",
        "# Some hyperparameters\r\n",
        "\r\n",
        "# 2.6 Batch size to train at one go:\r\n",
        "batch_size = 16             # No of batches = 4000/125 = 32\r\n",
        "                            # So per epoch we have 32 batches\r\n",
        "\r\n",
        "# 2.7 How many epochs of training?\r\n",
        "epochs = 5                  # For lack of time, let us make it just 5.\r\n",
        "\r\n",
        "# 2.8 No of test samples\r\n",
        "test_generator_samples = 300\r\n",
        "\r\n",
        "# 2.9 For test data, what should be batch size\r\n",
        "test_batch_size = 25    # This is different from training batch size\r\n",
        "\r\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmmw1NKlbaLP"
      },
      "source": [
        "\r\n",
        "# 3. About keras backend\r\n",
        "# 3.1 Can get backend configuration values, as:\r\n",
        "K.image_data_format()          # Read .keras conf file to findout\r\n",
        "K.backend()\r\n",
        "\r\n",
        "# 3.2 What is our backend and input_shape? Decide data shape as per that.\r\n",
        "#     Depth goes last in TensorFlow back-end, first in Theano\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    input_shape = (3, img_width, img_height)\r\n",
        "else:                                         # So, Tensorflow!\r\n",
        "    input_shape = (img_width, img_height, 3)\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2sn_fjjbdbi"
      },
      "source": [
        "\r\n",
        "# 4. Create convnet model\r\n",
        "#    con->relu->pool->con->relu->pool->con->relu->pool->flatten->fc->fc\r\n",
        "\r\n",
        "#     Call model constructor and then pass on a list of layers\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\r\n",
        "\r\n",
        "model = Sequential()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyAfWeuObhpN"
      },
      "source": [
        "# 4.1 Add Input layer\r\n",
        "model.add(Input(shape =input_shape ))\r\n",
        "# 4.2 Add Conv2D layer\r\n",
        "model.add(Conv2D(\r\n",
        "\t             filters=32,                # For every filter there is set of weights\r\n",
        "\t                                        # For each filter, one bias. So total bias = 32\r\n",
        "\t             kernel_size=(3, 3),        # For each filter there are 3*3=9 kernel_weights\r\n",
        "\t             strides = (1,1),           # So output shape will be 148 X 148 (W-F+1).\r\n",
        "\t                                        # Default strides is 1 only\r\n",
        "\t             #input_shape=input_shape,   # (150,150,3)\r\n",
        "\t             use_bias=True,             # Default value is True\r\n",
        "\t             padding='valid',           # 'valid' => No padding. This is default.\r\n",
        "\t             name=\"Ist_conv_layer\"\r\n",
        "\t             )\r\n",
        "         )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgpRNIFJbk_U",
        "outputId": "53152f37-65ea-43fa-ef06-efe2454c2922"
      },
      "source": [
        "# 4.3 So what have we done? Can you explain?\r\n",
        "#     Total weights = (kernel_weights) * RGB_channel * (filters)  + ToalNoBias\r\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "=================================================================\n",
            "Total params: 896\n",
            "Trainable params: 896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_lIIeX5as0f",
        "outputId": "f68255d5-65c2-4843-ed09-f2a4ee5bdad5"
      },
      "source": [
        "# 4.4 For each neuron in the convolved network,\r\n",
        "#     assign an activation function\r\n",
        "#     What is relu? See https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\r\n",
        "\r\n",
        "model.add(Activation('relu'))           # max {0,x}\r\n",
        "\r\n",
        "# 4.5\r\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "=================================================================\n",
            "Total params: 896\n",
            "Trainable params: 896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dtAvH0iEUwt",
        "outputId": "65ccfc9c-c94d-4bec-9d56-c5da6a9b5ae8"
      },
      "source": [
        "# 4.6 pool_size:  max pooling window size: (2,2)\r\n",
        "#     Default stride for pool-layer is same as pool_size\r\n",
        "#     Here: 2 across and 2 down ie (2,2)\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\r\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# 4.7\r\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "=================================================================\n",
            "Total params: 896\n",
            "Trainable params: 896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FouGt4g6EX0V",
        "outputId": "e84a9567-450e-4323-f6c4-ef67a5468f92"
      },
      "source": [
        "# 4.8 Input shape is inferred. Default strides is 1.\r\n",
        "#     Note: Activation is specified here only\r\n",
        "#     input_shape from top = 74 X 74 X 32\r\n",
        "model.add(Conv2D(32,\r\n",
        "                (3, 3),\r\n",
        "                activation = 'relu',\r\n",
        "                name = \"IInd_con_layer\"))\r\n",
        "\r\n",
        "# 4.9 So how many parameters now?\r\n",
        "#     Total weights = (kernel_weights) * (filters_from_earlier_conv) * (filters)  + ToalNoBias\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "=================================================================\n",
            "Total params: 10,144\n",
            "Trainable params: 10,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNT_fMZBEauR",
        "outputId": "1d5fc319-d995-4d1d-e763-52f09c941fe9"
      },
      "source": [
        "# model.add(Activation('relu'))\r\n",
        "\r\n",
        "# 4.10 Add another pooling layer\r\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# 4.11 Summary?\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "=================================================================\n",
            "Total params: 10,144\n",
            "Trainable params: 10,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0flqfb3Edm1",
        "outputId": "f7ee1309-318e-46e1-f52e-ec881378c5ab"
      },
      "source": [
        "# 4.12 Add another conv layer but with 64 filters\r\n",
        "#      Total weights = (kernel_weights) * (filters_from_earlier_conv) * (filters)  + ToalNoBias\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3, 3), name = \"IIIrd_conv_layer\"))\r\n",
        "\r\n",
        "# 4.13\r\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "IIIrd_conv_layer (Conv2D)    (None, 34, 34, 64)        18496     \n",
            "=================================================================\n",
            "Total params: 28,640\n",
            "Trainable params: 28,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tGjPXPlEgs9",
        "outputId": "51de11a3-a5d9-4e77-aaab-6755c9d62511"
      },
      "source": [
        "# 4.14\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "# 4.15\r\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# 4.16 Flattens the input. Does not affect the batch size.\r\n",
        "#      It merely flattens the earlier layer without adding any weight\r\n",
        "#     See summary() next\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\r\n",
        "\r\n",
        "model.add(Flatten(name = \"FlattenedLayer\"))\r\n",
        "\r\n",
        "# 4.17\r\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "IIIrd_conv_layer (Conv2D)    (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "FlattenedLayer (Flatten)     (None, 18496)             0         \n",
            "=================================================================\n",
            "Total params: 28,640\n",
            "Trainable params: 28,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpDg63noEm50",
        "outputId": "5e99a0dd-e7f8-4cda-efef-39b9430b49ad"
      },
      "source": [
        "# 4.18 Dense layer having 64 units\r\n",
        "#      dimensionality of the output space.\r\n",
        "#      Total weights = hidden_neurons * input_size + bias_foreach_hidden_neurons\r\n",
        "#      64 * 18496 + 64\r\n",
        "#      Most number of weights come from this layer\r\n",
        "#      https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\r\n",
        "\r\n",
        "model.add(Dense(64))\r\n",
        "\r\n",
        "# 4.19\r\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "IIIrd_conv_layer (Conv2D)    (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "FlattenedLayer (Flatten)     (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1183808   \n",
            "=================================================================\n",
            "Total params: 1,212,448\n",
            "Trainable params: 1,212,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gloedVGDEpnH",
        "outputId": "0611032a-858b-4e41-9028-c0d3f5587e51"
      },
      "source": [
        "# 4.20\r\n",
        "model.add(Activation('relu'))\r\n",
        "\r\n",
        "# Dropout\r\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "# 4.21\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "# 4.22 Dense layer having 1 unit\r\n",
        "#      dimensionality of the output space.\r\n",
        "#      Weights = No of input neurons + bias (64+1)\r\n",
        "model.add(Dense(1))\r\n",
        "\r\n",
        "# 4.23\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# 4.24\r\n",
        "model.add(Activation('sigmoid'))    # tanh vs sigmoid? See Stackoverflow\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "IIIrd_conv_layer (Conv2D)    (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "FlattenedLayer (Flatten)     (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1183808   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "=================================================================\n",
            "Total params: 1,212,448\n",
            "Trainable params: 1,212,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Ist_conv_layer (Conv2D)      (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "IInd_con_layer (Conv2D)      (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "IIIrd_conv_layer (Conv2D)    (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "FlattenedLayer (Flatten)     (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1183808   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,212,513\n",
            "Trainable params: 1,212,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAkfPNhcEvMB"
      },
      "source": [
        "# 4.25 Compile model\r\n",
        "model.compile(\r\n",
        "              loss='binary_crossentropy',  # Metrics to be adopted by convergence-routine\r\n",
        "              optimizer='rmsprop',         # Strategy for convergence?\r\n",
        "              metrics=['accuracy'])        # Metrics, I am interested in\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybM3o2bME1uC"
      },
      "source": [
        "\r\n",
        "#%%                            D. Create Data generators\r\n",
        "\r\n",
        "\r\n",
        "## 5. Image augmentation\r\n",
        "# 5.1 Define a preprocessing function\r\n",
        "def preprocess(img):\r\n",
        "\t# Histogram equalization\r\n",
        "\t# WITHOUT IT RESULTS ARE BETTER\r\n",
        "\t# http://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html\r\n",
        "    # img_eq = exposure.equalize_hist(img)\r\n",
        "    # Do something more with image\r\n",
        "    return img\r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcF8_5IE2_i"
      },
      "source": [
        "# 5.2 Config1: Augmentation configuration for training samples\r\n",
        "#     Instantiate ImageDataGenerator object with requisite configuration\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
        "\r\n",
        "tr_dtgen = ImageDataGenerator(\r\n",
        "                              rescale=1. / 255,      # Normalize colour intensities in 0-1 range\r\n",
        "                              shear_range=0.2,       # Shear varies from 0-0.2\r\n",
        "                              zoom_range=0.2,\r\n",
        "                              horizontal_flip=True,\r\n",
        "                              preprocessing_function=preprocess\r\n",
        "                              )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkaREic6E6Jj",
        "outputId": "8529fae1-a9d4-430d-d35d-907576fded04"
      },
      "source": [
        "\r\n",
        "# 5.3 Config2: Create iterator from 'train_datagen'.\r\n",
        "#     We use flow() or flow_from_directory() methods to further\r\n",
        "#     configure and return an iterator object.\r\n",
        "#     See at the end of code: Differences between flow()\r\n",
        "#     and flow_from_directory\r\n",
        "#     Pl see: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\r\n",
        "\r\n",
        "train_generator = tr_dtgen.flow_from_directory(\r\n",
        "                                               train_data_dir,       # Data folder of cats & dogs\r\n",
        "                                               target_size=(img_width, img_height),  # Resize images\r\n",
        "                                               batch_size=batch_size,  # Return images in batches\r\n",
        "                                               class_mode='binary'   # Output labels will be 1D binary labels\r\n",
        "                                                                     # [[1],[0],[0],[1]]\r\n",
        "                                                                     # If 'categorical' output labels will be\r\n",
        "                                                                     # 2D OneHotEncoded: [[1,0],[0,1],[0,1],[1,0]]\r\n",
        "                                                                     # If 'binary' use 'sigmoid' at output\r\n",
        "                                                                     # If 'categorical' use softmax at output\r\n",
        "\r\n",
        "                                                )\r\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP7fkFweFAx1"
      },
      "source": [
        "\r\n",
        "# 5.4 Augmentation configuration we will use\r\n",
        "#     for validation. Only rescaling of pixels\r\n",
        "\r\n",
        "val_dtgen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxgtc1hFDgt",
        "outputId": "69cf71fa-6382-48f4-e18e-57635f6d64f2"
      },
      "source": [
        "\r\n",
        "# 5.4.2 validation data\r\n",
        "validation_generator = val_dtgen.flow_from_directory(\r\n",
        "                                                     validation_data_dir,\r\n",
        "                                                     target_size=(img_width, img_height),   # Resize images\r\n",
        "                                                     batch_size=batch_size,    # batch size to augment at a time\r\n",
        "                                                     class_mode='binary'  # Return 1D array of class labels\r\n",
        "                                                     )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUafIHU3FGDd",
        "outputId": "9b0c3b5c-d607-4ae2-e0fb-875c5cd7d678"
      },
      "source": [
        "\r\n",
        "#%%                           E. Fit model & save CNN network weights\r\n",
        "\r\n",
        "\r\n",
        "## 6. Model fitting\r\n",
        "\r\n",
        "# 6.1 Manual process of fitting. Get infinite images\r\n",
        "#     Can experiment with infinite images. We will\r\n",
        "#     generate upto 3200 images\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\n",
        "\r\n",
        "start = time.time()   # 6 minutes\r\n",
        "for e in range(epochs):\r\n",
        "    print('Epoch', e)\r\n",
        "    batches = 0\r\n",
        "    for x_batch, y_batch in train_generator:\r\n",
        "        model.fit(x_batch, y_batch)\r\n",
        "        batches += 1\r\n",
        "        print (\"Epoch: {0} , Batches: {1}\".format(e,batches))\r\n",
        "        if batches > 200:    # 200 * 16 = 3200 images\r\n",
        "            # we need to break the loop by hand because\r\n",
        "            # the generator loops indefinitely\r\n",
        "            break\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "(end - start)/60\r\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6907 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 1\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 2.6257 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 2\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.8124 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 3\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7068 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 4\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6887 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 5\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7210 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 6\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6954 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 7\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.7255 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 8\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.7060 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 9\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6767 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 10\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 11\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6660 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 12\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6206 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 13\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.7877 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 14\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.7218 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 15\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7284 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 16\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7799 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 17\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6813 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 18\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6871 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 19\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6820 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 20\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7204 - accuracy: 0.3125\n",
            "Epoch: 0 , Batches: 21\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6905 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 22\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7111 - accuracy: 0.3125\n",
            "Epoch: 0 , Batches: 23\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.7086 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 24\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7022 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 25\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6904 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 26\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6854 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 27\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6757 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 28\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.7041 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 29\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6756 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 30\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.6929 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 31\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7089 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 32\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7178 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 33\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 34\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7081 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 35\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7046 - accuracy: 0.2500\n",
            "Epoch: 0 , Batches: 36\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 37\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6874 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 38\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6676 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 39\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7569 - accuracy: 0.2500\n",
            "Epoch: 0 , Batches: 40\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6778 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 41\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6756 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 42\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7234 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 43\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6870 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 44\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6700 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 45\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.7143 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 46\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7585 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 47\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6925 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 48\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 49\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7007 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 50\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 51\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 52\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6872 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 53\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6701 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 54\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.7399 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 55\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6830 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 56\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6905 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 57\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6806 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 58\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7275 - accuracy: 0.3125\n",
            "Epoch: 0 , Batches: 59\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7138 - accuracy: 0.1875\n",
            "Epoch: 0 , Batches: 60\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6937 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 61\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 62\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.8722 - accuracy: 0.2500\n",
            "Epoch: 0 , Batches: 63\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6918 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 64\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6906 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 65\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.7023 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 66\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6876 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 67\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6881 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 68\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6952 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 69\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6830 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 70\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.7088 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 71\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6849 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 72\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6807 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 73\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6220 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 74\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.9872 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 75\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6774 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 76\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6357 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 77\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6863 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 78\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6857 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 79\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6843 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 80\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7063 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 81\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 82\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6702 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 83\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7051 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 84\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6961 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 85\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6885 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 86\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6822 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 87\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6402 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 88\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.8305 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 89\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6934 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 90\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 91\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6691 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 92\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7290 - accuracy: 0.1875\n",
            "Epoch: 0 , Batches: 93\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6872 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 94\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6856 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 95\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6907 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 96\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6890 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 97\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6852 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 98\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6983 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 99\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 100\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7172 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 101\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6852 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 102\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6927 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 103\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6778 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 104\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7216 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 105\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 106\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6922 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 107\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6782 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 108\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 109\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6790 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 110\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6856 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 111\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6785 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 112\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5929 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 113\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 1.0811 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 114\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.7063 - accuracy: 0.3125\n",
            "Epoch: 0 , Batches: 115\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6706 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 116\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6885 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 117\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6935 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 118\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6616 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 119\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6290 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 120\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5908 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 121\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.9191 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 122\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6480 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 123\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6396 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 124\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7033 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 125\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6454 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 126\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6162 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 127\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.7304 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 128\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6506 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 129\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.6787 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 130\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.7290 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 131\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5795 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 132\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.6500 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 133\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6941 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 134\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7496 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 135\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7236 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 136\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6691 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 137\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7662 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 138\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6885 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 139\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6589 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 140\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.7304 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 141\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6574 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 142\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7313 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 143\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6781 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 144\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6792 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 145\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.6870 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 146\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7048 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 147\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6667 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 148\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6840 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 149\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6274 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 150\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.8491 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 151\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6827 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 152\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6629 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 153\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.7279 - accuracy: 0.2500\n",
            "Epoch: 0 , Batches: 154\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6921 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 155\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6685 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 156\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6760 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 157\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6879 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 158\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6497 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 159\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6355 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 160\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6232 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 161\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6788 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 162\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6545 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 163\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.6398 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 164\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.9274 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 165\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7035 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 166\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6665 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 167\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6595 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 168\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6819 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 169\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6703 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 170\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6445 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 171\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6006 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 172\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7574 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 173\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6442 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 174\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6825 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 175\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.7738 - accuracy: 0.3125\n",
            "Epoch: 0 , Batches: 176\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6554 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 177\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7091 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 178\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6503 - accuracy: 0.8125\n",
            "Epoch: 0 , Batches: 179\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6617 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 180\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.7004 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 181\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6779 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 182\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5669 - accuracy: 0.9375\n",
            "Epoch: 0 , Batches: 183\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.9116 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 184\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 185\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.6838 - accuracy: 0.6875\n",
            "Epoch: 0 , Batches: 186\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6726 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 187\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.6791 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 188\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6902 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 189\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6651 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 190\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6177 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 191\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 1.0846 - accuracy: 0.3750\n",
            "Epoch: 0 , Batches: 192\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7078 - accuracy: 0.5625\n",
            "Epoch: 0 , Batches: 193\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6536 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 194\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6745 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 195\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6597 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 196\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6646 - accuracy: 0.5000\n",
            "Epoch: 0 , Batches: 197\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6078 - accuracy: 0.7500\n",
            "Epoch: 0 , Batches: 198\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6721 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 199\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7684 - accuracy: 0.4375\n",
            "Epoch: 0 , Batches: 200\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6676 - accuracy: 0.6250\n",
            "Epoch: 0 , Batches: 201\n",
            "Epoch 1\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6718 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 1\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6371 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 2\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7067 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 3\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.7230 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 4\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6562 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 5\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7315 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 6\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6564 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 7\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6429 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 8\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6062 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 9\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5706 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 10\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7402 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 11\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6595 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 12\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7126 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 13\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6438 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 14\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5953 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 15\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6844 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 16\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.7104 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 17\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6238 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 18\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5658 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 19\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.7065 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 20\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6224 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 21\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7350 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 22\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6421 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 23\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.6342 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 24\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7742 - accuracy: 0.3125\n",
            "Epoch: 1 , Batches: 25\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 1.1876 - accuracy: 0.3125\n",
            "Epoch: 1 , Batches: 26\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6331 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 27\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5657 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 28\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6415 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 29\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7055 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 30\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6358 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 31\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6970 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 32\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6087 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 33\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.6813 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 34\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6669 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 35\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6563 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 36\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6156 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 37\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6308 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 38\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6641 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 39\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6655 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 40\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6645 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 41\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6105 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 42\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6453 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 43\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6775 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 44\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6446 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 45\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6851 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 46\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6875 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 47\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7418 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 48\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.6062 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 49\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6057 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 50\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.6825 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 51\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.7263 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 52\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6503 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 53\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.7272 - accuracy: 0.3125\n",
            "Epoch: 1 , Batches: 54\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6159 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 55\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6712 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 56\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6860 - accuracy: 0.3750\n",
            "Epoch: 1 , Batches: 57\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.7439 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 58\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6774 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 59\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6692 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 60\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5870 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 61\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6436 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 62\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6989 - accuracy: 0.3750\n",
            "Epoch: 1 , Batches: 63\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.9314 - accuracy: 0.3750\n",
            "Epoch: 1 , Batches: 64\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6528 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 65\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6918 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 66\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6677 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 67\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6085 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 68\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.6765 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 69\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6614 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 70\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6086 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 71\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5085 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 72\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.8172 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 73\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6781 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 74\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6995 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 75\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7699 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 76\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6774 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 77\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6615 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 78\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6173 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 79\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.6856 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 80\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6465 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 81\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6400 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 82\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6523 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 83\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6526 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 84\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5998 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 85\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.4920 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 86\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 87\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.6030 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 88\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5342 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 89\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 1.0018 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 90\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6032 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 91\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5788 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 92\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6732 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 93\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6122 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 94\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5071 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 95\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.7248 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 96\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.7338 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 97\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6201 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 98\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5308 - accuracy: 0.9375\n",
            "Epoch: 1 , Batches: 99\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.7466 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 100\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6300 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 101\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5954 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 102\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5762 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 103\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6398 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 104\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7470 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 105\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6006 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 106\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6132 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 107\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7694 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 108\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6284 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 109\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5576 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 110\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5214 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 111\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5772 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 112\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5848 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 113\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5926 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 114\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7360 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 115\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7560 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 116\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.8399 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 117\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6213 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 118\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7141 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 119\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6722 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 120\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.5611 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 121\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6516 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 122\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.7165 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 123\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6787 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 124\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6370 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 125\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6743 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 126\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5813 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 127\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5551 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 128\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6521 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 129\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6624 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 130\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6140 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 131\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6707 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 132\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6126 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 133\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6344 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 134\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5764 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 135\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4942 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 136\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6182 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 137\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6783 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 138\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.8171 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 139\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5080 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 140\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7837 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 141\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7655 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 142\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5986 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 143\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5877 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 144\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.5678 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 145\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5012 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 146\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.7118 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 147\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.6138 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 148\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6910 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 149\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.6358 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 150\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6533 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 151\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5938 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 152\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6591 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 153\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6797 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 154\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6327 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 155\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6323 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 156\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6231 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 157\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6127 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 158\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5521 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 159\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6510 - accuracy: 0.4375\n",
            "Epoch: 1 , Batches: 160\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5902 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 161\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6526 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 162\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7885 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 163\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4483 - accuracy: 0.9375\n",
            "Epoch: 1 , Batches: 164\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4708 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 165\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 166\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6474 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 167\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5273 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 168\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6506 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 169\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6522 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 170\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4267 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 171\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5258 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 172\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5671 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 173\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.4402 - accuracy: 0.8125\n",
            "Epoch: 1 , Batches: 174\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6257 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 175\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.7508 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 176\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6366 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 177\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6948 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 178\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.8240 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 179\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6548 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 180\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5492 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 181\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4888 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 182\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 183\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5167 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 184\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5627 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 185\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7271 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 186\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6430 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 187\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5413 - accuracy: 0.8750\n",
            "Epoch: 1 , Batches: 188\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6468 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 189\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.5323 - accuracy: 0.6875\n",
            "Epoch: 1 , Batches: 190\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6206 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 191\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4842 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 192\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6977 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 193\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6412 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 194\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6358 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 195\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7671 - accuracy: 0.5000\n",
            "Epoch: 1 , Batches: 196\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6168 - accuracy: 0.5625\n",
            "Epoch: 1 , Batches: 197\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6367 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 198\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.4292 - accuracy: 0.9375\n",
            "Epoch: 1 , Batches: 199\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6402 - accuracy: 0.7500\n",
            "Epoch: 1 , Batches: 200\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6128 - accuracy: 0.6250\n",
            "Epoch: 1 , Batches: 201\n",
            "Epoch 2\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6548 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 1\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6870 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 2\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6811 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 3\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6692 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 4\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4284 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 5\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6569 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 6\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6756 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 7\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.8083 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 8\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4971 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 9\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5707 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 10\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7846 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 11\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7169 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 12\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6629 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 13\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5199 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 14\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.7432 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 15\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.6308 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 16\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7022 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 17\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5927 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 18\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6023 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 19\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6422 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 20\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6280 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 21\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5020 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 22\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.4726 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 23\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7212 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 24\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7875 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 25\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5456 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 26\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5562 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 27\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.5285 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 28\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.4952 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 29\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.9066 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 30\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5792 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 31\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.4881 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 32\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5245 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 33\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5332 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 34\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.5129 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 35\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6480 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 36\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6000 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 37\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5126 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 38\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6176 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 39\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5563 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 40\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6588 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 41\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.4861 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 42\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6464 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 43\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6429 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 44\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5199 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 45\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.4995 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 46\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6303 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 47\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.8910 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 48\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.4900 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 49\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7873 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 50\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4660 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 51\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6605 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 52\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6090 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 53\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7031 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 54\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6244 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 55\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6356 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 56\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6297 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 57\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6357 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 58\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5054 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 59\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6030 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 60\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5683 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 61\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.8596 - accuracy: 0.3750\n",
            "Epoch: 2 , Batches: 62\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6733 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 63\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5773 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 64\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6342 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 65\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5986 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 66\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6725 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 67\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5581 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 68\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.5042 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 69\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6342 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 70\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.4973 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 71\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7597 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 72\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.5274 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 73\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 74\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.4247 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 75\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4977 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 76\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5977 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 77\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6704 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 78\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.3875 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 79\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6859 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 80\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.9438 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 81\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5036 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 82\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6729 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 83\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.4417 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 84\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6937 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 85\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.6820 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 86\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.5676 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 87\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.9811 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 88\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.4937 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 89\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4462 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 90\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.7345 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 91\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6209 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 92\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.6834 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 93\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.5915 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 94\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6617 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 95\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6165 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 96\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5006 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 97\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.7347 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 98\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5379 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 99\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5939 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 100\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5893 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 101\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6547 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 102\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6580 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 103\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5990 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 104\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.5946 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 105\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4459 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 106\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4072 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 107\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5740 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 108\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5790 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 109\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7040 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 110\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6062 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 111\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6760 - accuracy: 0.5000\n",
            "Epoch: 2 , Batches: 112\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.5247 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 113\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6742 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 114\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6747 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 115\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.4099 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 116\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5420 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 117\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5698 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 118\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5807 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 119\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4733 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 120\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5753 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 121\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4415 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 122\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5564 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 123\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5428 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 124\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6567 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 125\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6224 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 126\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.9111 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 127\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5653 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 128\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5430 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 129\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6220 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 130\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.5784 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 131\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6923 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 132\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6224 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 133\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4297 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 134\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6305 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 135\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.8300 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 136\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4477 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 137\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6037 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 138\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.7642 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 139\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6064 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 140\n",
            "1/1 [==============================] - 0s 418ms/step - loss: 0.4603 - accuracy: 0.9375\n",
            "Epoch: 2 , Batches: 141\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.7260 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 142\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.5490 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 143\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5286 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 144\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5833 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 145\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.4397 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 146\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6283 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 147\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.9289 - accuracy: 0.3750\n",
            "Epoch: 2 , Batches: 148\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5260 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 149\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4667 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 150\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5463 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 151\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5386 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 152\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.4436 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 153\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.7340 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 154\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6201 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 155\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5570 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 156\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5239 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 157\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.4751 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 158\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.4207 - accuracy: 0.8750\n",
            "Epoch: 2 , Batches: 159\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6413 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 160\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5691 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 161\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5727 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 162\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5002 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 163\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.3531 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 164\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 1.3182 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 165\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6940 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 166\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.8416 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 167\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.7004 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 168\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6053 - accuracy: 0.4375\n",
            "Epoch: 2 , Batches: 169\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5580 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 170\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.7433 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 171\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5788 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 172\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5327 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 173\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6739 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 174\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7737 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 175\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.4680 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 176\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5630 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 177\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6035 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 178\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7421 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 179\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6171 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 180\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5999 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 181\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5604 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 182\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5735 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 183\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5071 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 184\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.5060 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 185\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7832 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 186\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.3944 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 187\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.6067 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 188\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.4866 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 189\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.8922 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 190\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4747 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 191\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.5632 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 192\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.8204 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 193\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4390 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 194\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6880 - accuracy: 0.5625\n",
            "Epoch: 2 , Batches: 195\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.4157 - accuracy: 1.0000\n",
            "Epoch: 2 , Batches: 196\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6214 - accuracy: 0.7500\n",
            "Epoch: 2 , Batches: 197\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5722 - accuracy: 0.6250\n",
            "Epoch: 2 , Batches: 198\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.5500 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 199\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.4302 - accuracy: 0.8125\n",
            "Epoch: 2 , Batches: 200\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5476 - accuracy: 0.6875\n",
            "Epoch: 2 , Batches: 201\n",
            "Epoch 3\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.8909 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 1\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.7364 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 2\n",
            "1/1 [==============================] - 0s 426ms/step - loss: 0.7678 - accuracy: 0.3750\n",
            "Epoch: 3 , Batches: 3\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5314 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 4\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6217 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 5\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.4703 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 6\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.9985 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 7\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5937 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 8\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5174 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 9\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.9030 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 10\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4782 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 11\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5628 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 12\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.6938 - accuracy: 0.4375\n",
            "Epoch: 3 , Batches: 13\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.9793 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 14\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5480 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 15\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5921 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 16\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5104 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 17\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.7166 - accuracy: 0.4375\n",
            "Epoch: 3 , Batches: 18\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6661 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 19\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6015 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 20\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5914 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 21\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5680 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 22\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.5361 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 23\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6792 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 24\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4801 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 25\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6059 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 26\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4446 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 27\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6013 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 28\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5216 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 29\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6811 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 30\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6040 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 31\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5715 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 32\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.5307 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 33\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5982 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 34\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.5568 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 35\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.3876 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 36\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5522 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 37\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.3745 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 38\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.7911 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 39\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6137 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 40\n",
            "1/1 [==============================] - 0s 427ms/step - loss: 0.6095 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 41\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6045 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 42\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5327 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 43\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.3683 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 44\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.6489 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 45\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5318 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 46\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5499 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 47\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5574 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 48\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6417 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 49\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.7416 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 50\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5819 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 51\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5313 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 52\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6047 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 53\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5327 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 54\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.5634 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 55\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.4601 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 56\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6093 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 57\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5215 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 58\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5448 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 59\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4413 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 60\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.8109 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 61\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4346 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 62\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.4046 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 63\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.4113 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 64\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.3137 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 65\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.8098 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 66\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5763 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 67\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.3332 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 68\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.7992 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 69\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4290 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 70\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.4096 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 71\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.6704 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 72\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.4924 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 73\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4369 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 74\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4839 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 75\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.8033 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 76\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.6322 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 77\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6395 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 78\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.4012 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 79\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.9255 - accuracy: 0.3750\n",
            "Epoch: 3 , Batches: 80\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5245 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 81\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.2889 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 82\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5003 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 83\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6780 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 84\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5081 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 85\n",
            "1/1 [==============================] - 0s 418ms/step - loss: 0.5768 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 86\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4463 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 87\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5776 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 88\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5464 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 89\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.7829 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 90\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.7355 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 91\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6287 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 92\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6447 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 93\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5829 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 94\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5940 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 95\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.5595 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 96\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4506 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 97\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 0.5512 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 98\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7131 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 99\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4996 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 100\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5714 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 101\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5572 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 102\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.3862 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 103\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5165 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 104\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 0.7691 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 105\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.7896 - accuracy: 0.4375\n",
            "Epoch: 3 , Batches: 106\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6554 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 107\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6303 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 108\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5651 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 109\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6174 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 110\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.6066 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 111\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6633 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 112\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.7821 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 113\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4958 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 114\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.4764 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 115\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5225 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 116\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5184 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 117\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4639 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 118\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.4925 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 119\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7980 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 120\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5914 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 121\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5768 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 122\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.8731 - accuracy: 0.3125\n",
            "Epoch: 3 , Batches: 123\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4866 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 124\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.7578 - accuracy: 0.4375\n",
            "Epoch: 3 , Batches: 125\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.8090 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 126\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5974 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 127\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5362 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 128\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.3813 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 129\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6658 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 130\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.7259 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 131\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5545 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 132\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5063 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 133\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4325 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 134\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5703 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 135\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5637 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 136\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.3982 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 137\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7717 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 138\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7718 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 139\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6179 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 140\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.6994 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 141\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4990 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 142\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.5124 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 143\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7810 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 144\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5082 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 145\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4011 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 146\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6665 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 147\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5012 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 148\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5960 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 149\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.4596 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 150\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.4505 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 151\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.5469 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 152\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.4374 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 153\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.6410 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 154\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5325 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 155\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6720 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 156\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4532 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 157\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5290 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 158\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4922 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 159\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.8021 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 160\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.4581 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 161\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5100 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 162\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.4271 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 163\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7728 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 164\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5365 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 165\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.3678 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 166\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.7220 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 167\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 1.0030 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 168\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.8118 - accuracy: 0.3750\n",
            "Epoch: 3 , Batches: 169\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6145 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 170\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.6207 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 171\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5100 - accuracy: 0.9375\n",
            "Epoch: 3 , Batches: 172\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5952 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 173\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.7011 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 174\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6674 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 175\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5741 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 176\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6038 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 177\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.6443 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 178\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6466 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 179\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6260 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 180\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5572 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 181\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.4788 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 182\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6246 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 183\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6174 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 184\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5167 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 185\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.3875 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 186\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4866 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 187\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.6639 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 188\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5665 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 189\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.8090 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 190\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.6306 - accuracy: 0.5000\n",
            "Epoch: 3 , Batches: 191\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.5169 - accuracy: 0.6875\n",
            "Epoch: 3 , Batches: 192\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4375 - accuracy: 0.8750\n",
            "Epoch: 3 , Batches: 193\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5049 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 194\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6771 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 195\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5214 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 196\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6545 - accuracy: 0.5625\n",
            "Epoch: 3 , Batches: 197\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5986 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 198\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.4071 - accuracy: 0.8125\n",
            "Epoch: 3 , Batches: 199\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5172 - accuracy: 0.6250\n",
            "Epoch: 3 , Batches: 200\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.5574 - accuracy: 0.7500\n",
            "Epoch: 3 , Batches: 201\n",
            "Epoch 4\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6364 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 1\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5890 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 2\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.4321 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 3\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.4738 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 4\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6817 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 5\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.7209 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 6\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6551 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 7\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6875 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 8\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6035 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 9\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5505 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 10\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5134 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 11\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4988 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 12\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.3682 - accuracy: 0.9375\n",
            "Epoch: 4 , Batches: 13\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 1.1680 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 14\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 1.0564 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 15\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5691 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 16\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.5290 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 17\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5196 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 18\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.7679 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 19\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5351 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 20\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5011 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 21\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6038 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 22\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4996 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 23\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4764 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 24\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6118 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 25\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.6930 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 26\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.4066 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 27\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6775 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 28\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5107 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 29\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.6641 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 30\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6725 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 31\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5059 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 32\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7449 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 33\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.4689 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 34\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6606 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 35\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6483 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 36\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.4538 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 37\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6291 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 38\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5827 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 39\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.4953 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 40\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.3412 - accuracy: 1.0000\n",
            "Epoch: 4 , Batches: 41\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4524 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 42\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6798 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 43\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.8398 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 44\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.3904 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 45\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5298 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 46\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5564 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 47\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5464 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 48\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4375 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 49\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.4212 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 50\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6412 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 51\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4169 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 52\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.5793 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 53\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.7675 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 54\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6396 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 55\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6335 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 56\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.5555 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 57\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.9441 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 58\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.4745 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 59\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5510 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 60\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.4864 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 61\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.4740 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 62\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.4141 - accuracy: 0.9375\n",
            "Epoch: 4 , Batches: 63\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5876 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 64\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.4891 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 65\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.5942 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 66\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.7523 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 67\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5134 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 68\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5747 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 69\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6872 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 70\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.4832 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 71\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4799 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 72\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.6616 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 73\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.4472 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 74\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6170 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 75\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.4875 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 76\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4170 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 77\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.3971 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 78\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.8115 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 79\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.4623 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 80\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.5575 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 81\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.5946 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 82\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.7042 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 83\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5980 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 84\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5230 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 85\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.4915 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 86\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.3666 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 87\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.6281 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 88\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5032 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 89\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.5424 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 90\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.6758 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 91\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5902 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 92\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.3546 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 93\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.4804 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 94\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6753 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 95\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6621 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 96\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5711 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 97\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 1.0541 - accuracy: 0.4375\n",
            "Epoch: 4 , Batches: 98\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6349 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 99\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5335 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 100\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.3877 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 101\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.3745 - accuracy: 0.9375\n",
            "Epoch: 4 , Batches: 102\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.3963 - accuracy: 0.9375\n",
            "Epoch: 4 , Batches: 103\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.4844 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 104\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5782 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 105\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4316 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 106\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.6644 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 107\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4553 - accuracy: 0.9375\n",
            "Epoch: 4 , Batches: 108\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7485 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 109\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.6729 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 110\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.5402 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 111\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.6513 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 112\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.4332 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 113\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5007 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 114\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4527 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 115\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5420 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 116\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.5380 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 117\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4662 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 118\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5012 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 119\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5997 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 120\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.5697 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 121\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.5303 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 122\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5958 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 123\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.4616 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 124\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5452 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 125\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.4982 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 126\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.7916 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 127\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.7000 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 128\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.3991 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 129\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 0.5345 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 130\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.5418 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 131\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.4574 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 132\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.4228 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 133\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.2842 - accuracy: 1.0000\n",
            "Epoch: 4 , Batches: 134\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6093 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 135\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.3389 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 136\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 1.1426 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 137\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.8358 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 138\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5063 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 139\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.4385 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 140\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.8867 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 141\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.3820 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 142\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.3575 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 143\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 0.6655 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 144\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5091 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 145\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.7097 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 146\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5621 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 147\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.8531 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 148\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5952 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 149\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.6716 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 150\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7944 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 151\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7969 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 152\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.5634 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 153\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.5474 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 154\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.7024 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 155\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.5055 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 156\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.5355 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 157\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.6148 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 158\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6794 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 159\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6101 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 160\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.6315 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 161\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5354 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 162\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4980 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 163\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.3801 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 164\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.3387 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 165\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.5871 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 166\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.4689 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 167\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6394 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 168\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.4359 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 169\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 0.6784 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 170\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.5813 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 171\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 0.5412 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 172\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5240 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 173\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.6424 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 174\n",
            "1/1 [==============================] - 0s 401ms/step - loss: 0.4147 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 175\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5904 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 176\n",
            "1/1 [==============================] - 0s 411ms/step - loss: 0.5759 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 177\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.3931 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 178\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.5231 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 179\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.6538 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 180\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.6142 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 181\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.4838 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 182\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.4791 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 183\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.4036 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 184\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.3133 - accuracy: 1.0000\n",
            "Epoch: 4 , Batches: 185\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.4813 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 186\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.6171 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 187\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.5944 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 188\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.7883 - accuracy: 0.5000\n",
            "Epoch: 4 , Batches: 189\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.5834 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 190\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.5547 - accuracy: 0.5625\n",
            "Epoch: 4 , Batches: 191\n",
            "1/1 [==============================] - 0s 396ms/step - loss: 0.5212 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 192\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.4850 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 193\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 0.4090 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 194\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.5018 - accuracy: 0.8125\n",
            "Epoch: 4 , Batches: 195\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.6201 - accuracy: 0.6250\n",
            "Epoch: 4 , Batches: 196\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5593 - accuracy: 0.6875\n",
            "Epoch: 4 , Batches: 197\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4495 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 198\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.4261 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 199\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.4284 - accuracy: 0.8750\n",
            "Epoch: 4 , Batches: 200\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 0.6363 - accuracy: 0.7500\n",
            "Epoch: 4 , Batches: 201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.98195558389028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RqpE9dXFJZA",
        "outputId": "0e982670-f594-4a52-f778-2b405e49d8f4"
      },
      "source": [
        "# 6.2 fit_generator() directly pulls data from iterators\r\n",
        "#     But number of images cannot exceed those available\r\n",
        "#     Ref: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit_generator\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "history = model.fit_generator(\r\n",
        "                              generator = train_generator,          # First argument is always training data generator\r\n",
        "                              steps_per_epoch=nb_train_samples // batch_size, # How many batches per epoch?\r\n",
        "                                                                              # Can be any number as generator loops indefinitely\r\n",
        "                              epochs=epochs,                        # No of epochs\r\n",
        "                              validation_data=validation_generator, # Get validation data from validation generator\r\n",
        "                              verbose = 1,                          # Do not be silent\r\n",
        "                              validation_steps=nb_validation_samples // batch_size\r\n",
        "                              )\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "(end - start)/60\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "125/125 [==============================] - 73s 578ms/step - loss: 0.5473 - accuracy: 0.7465 - val_loss: 0.6819 - val_accuracy: 0.7013\n",
            "Epoch 2/5\n",
            "125/125 [==============================] - 72s 575ms/step - loss: 0.5320 - accuracy: 0.7340 - val_loss: 0.6004 - val_accuracy: 0.6687\n",
            "Epoch 3/5\n",
            "125/125 [==============================] - 72s 576ms/step - loss: 0.5087 - accuracy: 0.7660 - val_loss: 0.5623 - val_accuracy: 0.7337\n",
            "Epoch 4/5\n",
            "125/125 [==============================] - 72s 575ms/step - loss: 0.5229 - accuracy: 0.7470 - val_loss: 0.5465 - val_accuracy: 0.7450\n",
            "Epoch 5/5\n",
            "125/125 [==============================] - 72s 575ms/step - loss: 0.5245 - accuracy: 0.7575 - val_loss: 0.4918 - val_accuracy: 0.7663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.017813805739085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXyuLie-FMNi",
        "outputId": "16f44e92-82fc-4cf9-bcbb-3a85bdebef03"
      },
      "source": [
        "# 7.0 Model evaluation\r\n",
        "\r\n",
        "# 7.1 Using generator\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\r\n",
        "result = model.evaluate(validation_generator,\r\n",
        "                                  verbose = 1,\r\n",
        "                                  steps = 4        # How many batches\r\n",
        "                                  )\r\n",
        "\r\n",
        "\r\n",
        "# 7.1.1\r\n",
        "result     # ['loss', 'accuracy']"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 148ms/step - loss: 0.5154 - accuracy: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5153961181640625, 0.78125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baqy8F6qFPn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09yozLFCFVjI"
      },
      "source": [
        "\r\n",
        "# 8.0 Make predictions\r\n",
        "\r\n",
        "# 8.1 Using generator\r\n",
        "#     https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\r\n",
        "pred = model.predict(validation_generator, steps = 2)\r\n",
        "\r\n",
        "# 8.1.1\r\n",
        "pred\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq_cRw10FWMn"
      },
      "source": [
        "\r\n",
        "# 8.2 Manually\r\n",
        "pred = []\r\n",
        "steps = 0\r\n",
        "start = time.time()\r\n",
        "for x_batch, y_batch in validation_generator:\r\n",
        "        pred.append(model.predict(x_batch))\r\n",
        "        steps += 1\r\n",
        "        if steps >= 2:\r\n",
        "            # we need to break the loop by hand because\r\n",
        "            # the generator loops indefinitely\r\n",
        "            break\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "(end - start)/60\r\n",
        "\r\n",
        "# 8.2.1\r\n",
        "pred\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iQwoRMkFZUP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZkaGfsyIWx-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}