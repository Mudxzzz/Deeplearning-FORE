{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_hyperparameterOpt_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCsBI60R0ZDsgzwO/eCDk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning/blob/main/keras_hyperparameterOpt_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXFPiXMNAVs4"
      },
      "source": [
        "Last amended: 22nd Jan, 2021<br>\r\n",
        "Hyperparameter tuning example of Neural Network using keras-tuner of dense network<br>\r\n",
        "Ref:<br>\r\n",
        "https://keras-team.github.io/keras-tuner/ <br>\r\n",
        "https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html <br>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79S7WaM2ed9L"
      },
      "source": [
        "# 1.0 Install keras-tuner\r\n",
        "#     It is not a part of tensorflow package\r\n",
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f6eE40XKTtA"
      },
      "source": [
        "# 1.1 Import normal libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import kerastuner as kt\r\n",
        "\r\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPmMYHIKPDS5"
      },
      "source": [
        "# 1.2 Display outputs of multiple commands from a cell\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znxpyR84Kh5s"
      },
      "source": [
        "# 2.0 Get data.\r\n",
        "# Give a shortname for kears fashion_mnist module\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtjVxKNTMVeo"
      },
      "source": [
        "# 2.3 Download data. Data is downloaded. Download occurs only once.\r\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4PyeFXEMiv5",
        "outputId": "133e14f3-d7ea-43b9-85e7-7e614f60aca8"
      },
      "source": [
        "# 3.0 About data\r\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape  # ((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjJl-1SoMuBW",
        "outputId": "216075cd-3fa9-46a2-df5b-f52c868b9c81"
      },
      "source": [
        "# 3.1 Observe some pixel intensity values\r\n",
        "x_train[10,10,:10]\r\n",
        "y_train"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,  31, 174,  28, 126, 153], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmKQMJprNLI1",
        "outputId": "db440422-6d94-4516-c41a-897ea7307528"
      },
      "source": [
        "# 3.2 Nomalize pixel intensities\r\n",
        "x_train = x_train/255\r\n",
        "x_test = x_test/255\r\n",
        "x_train[10,10,:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.12156863, 0.68235294, 0.10980392, 0.49411765, 0.6       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzWG29FrNaEU"
      },
      "source": [
        "# 3.3 Corresponding to values 0,1,2..9 in the target, the \r\n",
        "#  names of actual items are here:\r\n",
        "items = [ \"T-shirt/top\",\"Trouser\", \"Pullover\", \"Dress\" , \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\" ]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yHvnpa2ZRiVK",
        "outputId": "de9b5373-ed8b-4013-cff6-7c78a563b581"
      },
      "source": [
        "# 3.4 So which items are represented by y_train[0] and y_train[10]\r\n",
        "items[y_train[0]]\r\n",
        "items[y_train[10]]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ankle boot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T-shirt/top'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYSZuPrBBeX8"
      },
      "source": [
        "Experiments with diff weight initialization techniques<br>\r\n",
        "Just for fun, we will use different weight initilizers<br>\r\n",
        "Ref: https://keras.io/api/layers/initializers/\r\n",
        "\r\n",
        "> **GlorotNormal**:\r\n",
        "Draws samples from a truncated normal distribution centered on 0 with stddev = *sqrt(2 / (fan_in + fan_out))* where *fan_in* is the number of input units in the weight tensor and *fan_out* is the number of output units in the weight tensor.<br>\r\n",
        "**GlorotUniform**:\r\n",
        "Draws samples from a uniform distribution within *[-limit, limit]*, where limit = *sqrt(6 / (fan_in + fan_out))* (*fan_in* is the number of input units in the weight tensor and *fan_out* is the number of output units)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oacV8A-qRl32"
      },
      "source": [
        "# 4.0 Let us build our dense NN model\r\n",
        "from tensorflow.keras import initializers \r\n",
        "# Dense layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\r\n",
        "model = keras.models.Sequential(\r\n",
        "                                  [\r\n",
        "                                    keras.layers.Flatten(input_shape = (28,28)),\r\n",
        "                                    keras.layers.Dense(100,activation = 'relu', kernel_initializer=initializers.RandomNormal(stddev=0.01), name = \"Ist\"),\r\n",
        "                                    keras.layers.Dense(100,activation = 'relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = \"IInd\"),\r\n",
        "                                    keras.layers.Dense(100,activation = 'relu', name = \"IIIrd\" ),\r\n",
        "                                    keras.layers.Dense(10, activation = \"softmax\")\r\n",
        "                                  ]\r\n",
        "                               )"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C9eQQlFYQPq",
        "outputId": "54b7f51e-2307-42bf-c805-48b9a2eadb5e"
      },
      "source": [
        "# 4.1 Get a summary of what layers are in our model\r\n",
        "#     Does not give more details, such as activation etc,\r\n",
        "#     about each layer\r\n",
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "Ist (Dense)                  (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "IInd (Dense)                 (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "IIIrd (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 99,710\n",
            "Trainable params: 99,710\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83xltvitXHAm",
        "outputId": "7a989f27-d515-42d3-bc14-6e7a3e128d68"
      },
      "source": [
        "# 4.2 Let us look at model.layers object\r\n",
        "#     Contains a list of layers and memory addresses\r\n",
        "model.layers"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Flatten at 0x7f882f16f470>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f882f16f668>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f882f16f940>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f882f16fba8>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f882f16feb8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yYKuijFsYiGv",
        "outputId": "12e175be-981c-4edd-aff7-b7e4d9b4477c"
      },
      "source": [
        "# 4.3 First layer is Flatten layer. IInd \r\n",
        "#     and IIIrd layers are hidden layers.\r\n",
        "#     What is its name?\r\n",
        "first_hid_layer = model.layers[1]\r\n",
        "first_hid_layer.name   # dense\r\n",
        "model.layers[2].name   # dense_1"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IInd'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCuvcZFSR7C_"
      },
      "source": [
        "# 4.4 Get weights and biases of Ist hidden layer\r\n",
        "weights,biases = first_hid_layer.get_weights()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0lPjcqWw1-",
        "outputId": "e345e876-04f5-4652-b1d2-54a4db46e2e1"
      },
      "source": [
        "# 4.5 Print \r\n",
        "weights\r\n",
        "print(\"\\n\")\r\n",
        "weights.shape    # (784, 100) \r\n",
        "                 # For each neuron in hidden layer, \r\n",
        "                 # there are 784 input weights\r\n",
        "print(\"\\n\")\r\n",
        "biases.shape     # (100,) For each neuron, there is one bias            "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.2759978e-03, -7.1604284e-03, -2.3670425e-03, ...,\n",
              "         1.5191697e-02, -1.3541132e-02, -3.3133547e-03],\n",
              "       [ 1.1934866e-02,  1.2985159e-02,  1.8728822e-02, ...,\n",
              "        -1.6895626e-02,  9.6656652e-03, -4.9827620e-03],\n",
              "       [-1.2851831e-02, -3.4100031e-03, -2.5947299e-03, ...,\n",
              "        -4.4917017e-03, -1.4146616e-02, -7.1270806e-03],\n",
              "       ...,\n",
              "       [ 4.1175634e-04,  4.9299335e-05, -5.3887772e-03, ...,\n",
              "        -8.6481273e-03,  5.4882369e-03, -6.1746943e-03],\n",
              "       [-5.7845801e-04, -2.0908741e-02, -1.0567525e-02, ...,\n",
              "        -9.2661269e-03,  1.4854411e-02, -6.6311395e-04],\n",
              "       [ 1.8915642e-02, -1.0871917e-02,  8.8882940e-03, ...,\n",
              "         1.2192859e-03,  8.4017403e-03, -6.5717101e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "G1Jr-irj4ASZ",
        "outputId": "57db0296-3bc9-4ee6-b8e1-1c554b59f95d"
      },
      "source": [
        "# 5.0 Let us draw a histogram of weights\r\n",
        "#     arriving at IInd neuron in the hidden layer\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_subplot(1,1,1)\r\n",
        "ax.hist(weights[:,1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  7.,  14.,  67., 113., 179., 191., 135.,  53.,  17.,   8.]),\n",
              " array([-2.9785559e-02, -2.3845997e-02, -1.7906435e-02, -1.1966874e-02,\n",
              "        -6.0273120e-03, -8.7750144e-05,  5.8518117e-03,  1.1791374e-02,\n",
              "         1.7730935e-02,  2.3670496e-02,  2.9610058e-02], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5w4Y8kuW4M0",
        "outputId": "87d366cb-4535-4f8e-f8ea-85315a85bd72"
      },
      "source": [
        "# 5.1 Print biases\r\n",
        "biases\r\n",
        "biases.shape    # (100,)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUdFe-PUZKTX"
      },
      "source": [
        "# 6.0 Finally compile the model\r\n",
        "model.compile(\r\n",
        "               loss = 'sparse_categorical_crossentropy',\r\n",
        "               optimizer = 'rmsprop',   # This is the default\r\n",
        "               metrics = ['accuracy']\r\n",
        "              )"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLMvL1hpdWfU",
        "outputId": "d8709ef7-8f57-497d-cd2b-9d3b253ba7be"
      },
      "source": [
        "# 6.1 Train the model now\r\n",
        "model.fit(\r\n",
        "           x_train,y_train,\r\n",
        "           epochs = 10,\r\n",
        "           verbose = 1\r\n",
        "          )"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6776 - accuracy: 0.7516\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3988 - accuracy: 0.8560\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3675 - accuracy: 0.8699\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3556 - accuracy: 0.8760\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3566 - accuracy: 0.8756\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3532 - accuracy: 0.8795\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3548 - accuracy: 0.8788\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3570 - accuracy: 0.8785\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3520 - accuracy: 0.8797\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3539 - accuracy: 0.8798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f884a3947f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9fjUEkl7-HV"
      },
      "source": [
        "**Tuning a keras model**<br>\r\n",
        "> Step1: Build NN model with one argument, 'hp'<br>\r\n",
        "> Step2: Design/instantiate keras-tuner<br>\r\n",
        "> Step3: Run/execute tuner <br>\r\n",
        "> Step4: Print results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfikqZWMdseL"
      },
      "source": [
        "# 7.0 Define a function that builds NN model\r\n",
        "# and returns an NN model. It takes one argument\r\n",
        "\r\n",
        "def build_model(hp):\r\n",
        "   \"\"\"Basic case:\r\n",
        "      - We define a `build_model` function\r\n",
        "      - It returns a compiled model\r\n",
        "      - It uses hyperparameters defined on the fly\r\n",
        "   \"\"\"\r\n",
        "   # 7.1 How many neurons in Ist hidden layer \r\n",
        "   n_size1 = hp.Int('n_size1', 32, 200, default=64)\r\n",
        "   n_size2 = hp.Int('n_size2', 32, 200, default=64)\r\n",
        "\r\n",
        "   # 7.2 Extent of dropout\r\n",
        "   dropout1 = hp.Float('dropout1', 0, 0.5, step=0.1, default=0.5)\r\n",
        "   dropout2 = hp.Float('dropout2', 0, 0.5, step=0.1, default=0.5)\r\n",
        "\r\n",
        "   # 7.3 Which activation\r\n",
        "   activation = hp.Choice('activation' , ['relu', 'tanh'])\r\n",
        "\r\n",
        "   # 7.4 Build model\r\n",
        "   model = keras.models.Sequential(\r\n",
        "                                    [\r\n",
        "                                      keras.layers.Flatten(input_shape = [28,28]),\r\n",
        "                                      keras.layers.Dense(n_size1,activation = activation),\r\n",
        "                                      keras.layers.Dropout(dropout1),\r\n",
        "                                      keras.layers.Dense(n_size2,activation = activation),\r\n",
        "                                      keras.layers.Dropout(dropout2),\r\n",
        "                                      keras.layers.Dense(10, activation = \"softmax\")\r\n",
        "                                    ]\r\n",
        "                                  )\r\n",
        "   # 7.5 Compile model\r\n",
        "   model.compile(\r\n",
        "                 loss = 'sparse_categorical_crossentropy',\r\n",
        "                 optimizer=keras.optimizers.Adam(\r\n",
        "                                                   hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\r\n",
        "                                                 ),\r\n",
        "                 metrics = ['accuracy'])\r\n",
        "   \r\n",
        "   return model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yzvG9vYhYE"
      },
      "source": [
        "**Design tuner**<br>\r\n",
        "Instantiate a tuner<br>\r\n",
        "(Three methods)<br>\r\n",
        "> In the tuner(), you should specify the model-building function (*build()*), the name of the *objective* to optimize (whether to minimize or maximize is automatically inferred for built-in metrics), the total number of trials (*max_trials*) to test, and the number of models that should be built and fit for each trial (*executions_per_trial*).<br><br>\r\n",
        "**Note**: the purpose of having multiple executions per trial is to reduce results variance and therefore be able to more accurately assess the performance of a model. Within a given *trial* (say, trial=20), an '*hp*' is created. For each '*execution_per_trial*', *build()* is called and the same '*hp*' is passed. But selected parameter values by the same '*hp*' can be different. If you want to get results faster, you could set executions_per_trial=1 (single round of training for each model configuration)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saC8XjVGXaOH"
      },
      "source": [
        "# 8.1 Method 1\r\n",
        "# Tune by pure random search\r\n",
        "# What is 'executions_per_trial'\r\n",
        "#  See: https://datascience.stackexchange.com/a/72292/64849\r\n",
        "tuner_r = kt.RandomSearch(\r\n",
        "                        build_model,              # Keras model to train\r\n",
        "                        objective='val_accuracy', # Maximise/Minimise objective \r\n",
        "                        seed = 123,\r\n",
        "                        max_trials = 5,           # Total number of trials to test at most.\r\n",
        "                        executions_per_trial= 3,  # For each trial, run as many executions\r\n",
        "                                                  # as in execution_per_trial. Given the randomness that\r\n",
        "                                                  # exist in the optimization process, there may be some variation in\r\n",
        "                                                  # the set of parameter selected by 'hp'. Final results could be very\r\n",
        "                                                  # different. For each trial and execution, the tuner will fit the\r\n",
        "                                                  #  model with as many epochs as you configure in the script.\r\n",
        "                        directory='random_search',\r\n",
        "                        overwrite=True,           # Overwrite results of last 'tuner'\r\n",
        "                        project_name='fashion_mnist'\r\n",
        "                      )"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbJz7qHLe5uo"
      },
      "source": [
        "# 8.2 Method 2\r\n",
        "# Tune by optimized random search\r\n",
        "# Hyperband is an optimized version of \r\n",
        "# random search which uses early-stopping\r\n",
        "# to speed up the hyperparameter tuning process. \r\n",
        "# The main idea is to fit a large number of \r\n",
        "# models for a small number of epochs and to\r\n",
        "# only continue training for the models \r\n",
        "# achieving the highest accuracy on the \r\n",
        "# validation set. The max_epochs variable\r\n",
        "# is the max number of epochs that a model \r\n",
        "# can be trained for.\r\n",
        "\r\n",
        "#tuner_h = kt.Hyperband(\r\n",
        "#                     build_model,\r\n",
        "#                     objective='val_accuracy',\r\n",
        "#                     max_epochs=10,\r\n",
        "#                     overwrite=True,            # Overwrite results of last 'tuner'\r\n",
        "#                     hyperband_iterations=2\r\n",
        "#                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp78sSmvQpXb"
      },
      "source": [
        "# 8.3 Method 3\r\n",
        "# Tune by Bayesian optimization\r\n",
        "# Same signatures as of RandomSearch()\r\n",
        "tuner_b = kt.tuners.BayesianOptimization(\r\n",
        "                                       build_model,\r\n",
        "                                       objective='val_accuracy',\r\n",
        "                                       overwrite=True,  # Overwrite results of last 'tuner'\r\n",
        "                                       max_trials=5,\r\n",
        "                                       executions_per_trial= 3,\r\n",
        "                                       )"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3JhoFwjuCN_"
      },
      "source": [
        "**Start tuning**<br>\r\n",
        "Invoke search() function<br>\r\n",
        "> Here's what happens in search(): models are built iteratively by calling the model-building function, which populates the hyperparameter space (search space) tracked by the '*hp*' object. *Each call to build() may set different parameter combination.* The tuner progressively explores the space, recording metrics for each configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBTKlYv0fLc8",
        "outputId": "1aa59591-b9ad-4403-f927-4e5ae4feaf17"
      },
      "source": [
        "# 9.0 Start tuning\r\n",
        "# This is common to all three methods of tuning\r\n",
        "# The call to search has the same signature as model.fit()\r\n",
        "# Here's what happens in search: models are built iteratively\r\n",
        "#  by calling the model-building function, which populates the\r\n",
        "#   hyperparameter space (search space) tracked by the hp object. \r\n",
        "#     The tuner progressively explores the space, recording metrics\r\n",
        "#       for each configuration.\r\n",
        "\r\n",
        "# Total elapsed time: 00h 04m 46s\r\n",
        "\r\n",
        "tuner_r.search(\r\n",
        "             x_train,y_train,\r\n",
        "             validation_data=(x_test,y_test),\r\n",
        "             epochs=5,  # For each max_trials (5), \r\n",
        "                        #   there are sub-trials (3). \r\n",
        "                        #    For each sub-trial, 5-epochs\r\n",
        "                        #     To speed         \r\n",
        "             callbacks=[\r\n",
        "                        tf.keras.callbacks.EarlyStopping(patience=1)   # The more the patience more the epochs\r\n",
        "                        ] \r\n",
        "             )"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 01m 38s]\n",
            "val_accuracy: 0.8675000071525574\n",
            "\n",
            "Best val_accuracy So Far: 0.8677333196004232\n",
            "Total elapsed time: 00h 05m 35s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PORLW6rq6ZJL"
      },
      "source": [
        "# 9.1 Tuning through Hyperband search\r\n",
        "#     Number of trials may be upto 60\r\n",
        "\r\n",
        "# Total elapsed time: 00h 14m 00s\r\n",
        "\r\n",
        "#tuner_h.search(x_train,y_train,\r\n",
        "#             validation_data=(x_test,y_test),\r\n",
        "#             epochs=10,\r\n",
        "#             callbacks=[\r\n",
        "#                        tf.keras.callbacks.EarlyStopping(patience=1)\r\n",
        "#                        ] \r\n",
        "#             )"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHd-5Vgj6c_2",
        "outputId": "8c2fb014-73a2-4c14-804c-b7c4df240d11"
      },
      "source": [
        "# 9.2 Tuning through Bayesian search\r\n",
        "\r\n",
        "# Total elapsed time: 00h 03m 34s\r\n",
        "\r\n",
        "tuner_b.search(x_train,y_train,\r\n",
        "             validation_data=(x_test,y_test),\r\n",
        "             epochs=5,       # This value should be high\r\n",
        "             callbacks=[\r\n",
        "                        tf.keras.callbacks.EarlyStopping(patience=1)\r\n",
        "                        ] \r\n",
        "             )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 02m 29s]\n",
            "val_accuracy: 0.8700000047683716\n",
            "\n",
            "Best val_accuracy So Far: 0.8700000047683716\n",
            "Total elapsed time: 00h 08m 42s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkB_kbJOLbfX",
        "outputId": "262f6e61-93d6-4cd0-d7f8-8461da34ef22"
      },
      "source": [
        "# 9.3 Show a summary of the RandomSearch space\r\n",
        "print(\"\\n1. Random Search results summary\")\r\n",
        "tuner_r.results_summary()\r\n",
        "#print(\"\\n2. Hyperband results summary\")\r\n",
        "#tuner_h.results_summary()\r\n",
        "print(\"\\n3. Bayesian results summary\")\r\n",
        "tuner_b.results_summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1. Random Search results summary\n",
            "Results summary\n",
            "Results in random_search/fashion_mnist\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 130\n",
            "n_size2: 119\n",
            "dropout1: 0.2\n",
            "dropout2: 0.2\n",
            "activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.8677333196004232\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 134\n",
            "n_size2: 100\n",
            "dropout1: 0.0\n",
            "dropout2: 0.4\n",
            "activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.8675000071525574\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 144\n",
            "n_size2: 129\n",
            "dropout1: 0.0\n",
            "dropout2: 0.1\n",
            "activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.8151666720708212\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 119\n",
            "n_size2: 130\n",
            "dropout1: 0.5\n",
            "dropout2: 0.2\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.7469333410263062\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 41\n",
            "n_size2: 193\n",
            "dropout1: 0.5\n",
            "dropout2: 0.30000000000000004\n",
            "activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.6293666760126749\n",
            "\n",
            "3. Bayesian results summary\n",
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 200\n",
            "n_size2: 32\n",
            "dropout1: 0.0\n",
            "dropout2: 0.0\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.8700000047683716\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 101\n",
            "n_size2: 99\n",
            "dropout1: 0.1\n",
            "dropout2: 0.2\n",
            "activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.856333335240682\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 32\n",
            "n_size2: 200\n",
            "dropout1: 0.0\n",
            "dropout2: 0.0\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.8551000157992045\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 32\n",
            "n_size2: 32\n",
            "dropout1: 0.5\n",
            "dropout2: 0.5\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.8074333270390829\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_size1: 184\n",
            "n_size2: 183\n",
            "dropout1: 0.1\n",
            "dropout2: 0.4\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.7622333367665609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSnIHcxC2v62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520f9ae8-132a-4bb0-f786-bbe8cc395916"
      },
      "source": [
        "# 10.0 Retrieve the best model.\r\n",
        "best_model_r = tuner_r.get_best_models(num_models=1)[0]\r\n",
        "#best_model_h = tuner_h.get_best_models(num_models=1)[0]\r\n",
        "best_model_b = tuner_b.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzDSIhva91OZ",
        "outputId": "17ce29f8-ac1b-45e0-da66-a6cf50d7c9f1"
      },
      "source": [
        "print(\"\\n1. Random Search best model\")\r\n",
        "best_model_r\r\n",
        "#print(\"\\n2. Hyperband results best model\")\r\n",
        "#best_model_h\r\n",
        "print(\"\\n3. Bayesian results best model\")\r\n",
        "best_model_b"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1. Random Search best model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f882f227cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "3. Bayesian results best model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f882fc5fb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI7hjcP11rzG",
        "outputId": "34530c6d-3d81-4ecf-db74-5e02862b37fd"
      },
      "source": [
        "# 10.1 Evaluate the best model.\r\n",
        "loss_r, accuracy_r = best_model_r.evaluate(x_test, y_test)\r\n",
        "#loss_h, accuracy_h = best_model_h.evaluate(x_test, y_test)\r\n",
        "loss_b, accuracy_b = best_model_b.evaluate(x_test, y_test) "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8764\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFe1H6tvBrkR",
        "outputId": "71fed5e9-bbec-4a55-b3a1-b5bd40c5dd10"
      },
      "source": [
        "print(\"\\n1. Random Search Evaluation\")\r\n",
        "loss_r, accuracy_r\r\n",
        "#print(\"\\n2. Hyperband results Evaluation\")\r\n",
        "#loss_h, accuracy_h\r\n",
        "print(\"\\n3. Bayesian results Evaluation\")\r\n",
        "loss_b, accuracy_b"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1. Random Search Evaluation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.34174400568008423, 0.8748999834060669)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "3. Bayesian results Evaluation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35246095061302185, 0.8755000233650208)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCCm8m1F--7O"
      },
      "source": [
        "####### I am done ########################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}