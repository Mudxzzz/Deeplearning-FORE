# Examples used in my DeepLearning Class

**File: cats_dogs_classification.ipynb**<br>
*Objectives:*

- Building powerful image classification models using  very little data
- Using image data-augmentation techniques
- Predicting cats and dogs--[Kaggle](https://www.kaggle.com/c/dogs-vs-cats)
- Calcualting model weights, stage-by-stage
- Saving model-weights and model-architecture to files
- Loading saved model-architecture and model-weights
------------
**File: cifar10_classification.ipynb**<br>
*Objective:*

- CIFAR10 image classification using deep learning


------------
**File: cifar10_classification_functionalModeling.ipynb**<br>
*Objective:*

- CIFAR10 image classification with deep-learning CNN
- Building Functional models  (Use GPU not CPU)

------------
**File: classify_with_vgg16_softmax.ipynb**<br>
*Objectives:*

- Transfer Learning:     Building powerful image classification models using very little data using  pre-trained applications
- Feature Enngineering: Using engineered features with Random Forest Classifier
- Learning Rate Annealing: Moderating Learning rate on/near plateau 
------------
**File: generators in python.ipynb**<br>
*Objectives:*

- How a generator works
- Applications of a generator
------------
**File: expts_with_mobilenet.ipynb**<br>
*Objectives:*

- Using mobilenet
- Using mobilenet on browser
- Using Image Augmentaion techniques from libraries other than tensorflow/keras
- Transfer learning using Mobilenet
------------
**File: keras_functional.ipynb**<br>
*Objective:*

- Using keras functional API

------------

**File: image_augmentation.ipynb**<br>
*Objective(s):*

How Image augmentation is performed.
Image augmentation basics

------------
**File: learningRateScheduler_tensorbard.ipyb******<br>
*Objectives: *

- To use multiple callbacks
- To use learning-rate scheduler
- To see results on tensorboard
------------
**File(s):<br>
keras_hyperparameterOpt_class.ipynb  
keras_hyperparameterOpt.ipynb**

*Objective:*

- Hyperparameter tuning example of Neural Network using keras-tuner of dense network

------------
**File: plot_vgg16_layer_features.ipynb**<br>
*Objectives:*

- Experimenting with Very Deep ConvNets: VGG16
- Peeping into layers and plotting extracted-features
- Visualize filters
------------
**File: pretrained_layers_autoencoder_I.ipynb**<br>
*Objectives*

- Building autoencoder using Model class subclassing
- Using pre-trained autoencoder layers in a classifier
- Comparing Classifer performance with and without pre-trained 
- Using keras model as a layer
- A pre-trained model using autoencoder gives better classification

------------

**File: pretrained_layers_autoencoder_II.ipynb**<br>
*Objectives:*

- Building autoencoder using Model class subclassing
- Training autoencoder with gaussian noise added 
- Using pre-trained autoencoder layers in a classifier
- Comparing Classifer performance with and without pre-trained 
- Using keras model as a layer
- A pre-trained model using autoencoder-with-noise added gives better classification

------------
**File: pretrained_layers_autoencoder_III.ipynb**<br>
*Objectives*

- Building autoencoder using Model class subclassing
- Building autoencoder using Functional API 
- Training autoencoder with gaussian noise added 
- Using pre-trained autoencoder layers in a classifier
- Comparing Classifer performance with and without pre-trained 
- Using keras model as a layer
- A pre-trained model using autoencoder-with-noise added gives better classification

------------

**File: subClassingKerasModel.ipynb**<br>
*Objective:*

- Subclassing keras 'Model' class to create Dynamic models
- Two examples

------------
**File: reusing_trained_layers.ipynb**<br>
*Objective: *

- Reuse layers from one neural network in another.
- Ist model was trained using a different set of class labels than present in the IInd case


------------






