{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "John Labs sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/deeplearning/blob/main/John_Labs_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Sentiment Prediction in English text**\n",
        "Refer [here](https://nlp.johnsnowlabs.com/docs/en/annotators#classifierdl) <br>\n",
        "For appropriate spark-nlp models and pipeline make a search [here](https://nlp.johnsnowlabs.com/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eobhtJxmHd9"
      },
      "source": [
        "Trains a `ClassifierDL` for generic Multi-class Text Classification. \n",
        "\n",
        "`ClassifierDL` uses the state-of-the-art `Universal Sentence Encoder` as an input for text classifications. The `ClassifierDL` annotator uses a deep learning model (DNNs) built inside TensorFlow and supports up to 100 classes.\n",
        "\n",
        "For instantiated/pretrained models, see ClassifierDLModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC7zYsccm_Kz"
      },
      "source": [
        "Note: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup\n",
        "Install spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9az4p8egymY"
      },
      "source": [
        "# 1.0 Installs pyspark, spark-nlp and findspark\n",
        "\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKDliST0g0Bn"
      },
      "source": [
        "#1.1  To check contents of colab.sh, just download \n",
        "#     colab.sh and examine its contents:\n",
        "\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh \n",
        "\n",
        "! cat /content/colab.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n"
      },
      "source": [
        "# Install Spark NLP Display for visualization\n",
        "# !pip install --ignore-installed spark-nlp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session\n",
        "Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "# 2.0 Call libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType, StringType,StructField,StructType\n",
        "#Replace part of string with another string\n",
        "from pyspark.sql.functions import regexp_replace"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ2UWVCllv57"
      },
      "source": [
        "# 2.1 Create Spark session\n",
        "#     And start sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzfXA4VnX36"
      },
      "source": [
        "# 2.2 Show multiple command outputs from a cell\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_BipeEUFtd"
      },
      "source": [
        "## Mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCR4fpdTZFKK",
        "outputId": "9b30b96e-f97e-433b-8410-d37a27efc3bc"
      },
      "source": [
        "# 2.3 Mount gdrive to read data\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jde_sSWcbqRp"
      },
      "source": [
        "# 3.0\n",
        "path = \"/gdrive/MyDrive/Colab_data_files/corona_nlp/Corona_NLP_test.csv\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S90CG1rdlIb0"
      },
      "source": [
        "The csv dataset should just have two columns, *text* and *label*. *label* can be string also.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAL0eyJXhhrH"
      },
      "source": [
        "### Read using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_psAsJWhkrD"
      },
      "source": [
        "# 3.1 Read dataset using pandas\n",
        "f = pd.read_csv(path)\n",
        "f.head()\n",
        "f.shape\n",
        "f['Sentiment'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq-SjK71h28X"
      },
      "source": [
        "# 3.2 Transform pandas to spark dataframe\n",
        "g = f[['OriginalTweet','Sentiment']].copy()\n",
        "cor_data =spark.createDataFrame(g)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mEAFbbbh9fj"
      },
      "source": [
        "# 3.3 Examine it\n",
        "cor_data.show()\n",
        "cor_data.count()      # 3798"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFGiK_r2iSCz"
      },
      "source": [
        "### Read using pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpEXHIqiiW1m"
      },
      "source": [
        "# 4.0 Read data directly in spark a normal manner:\n",
        "\n",
        "data = spark.read.csv(\n",
        "                      path = path,\n",
        "                      inferSchema=True,\n",
        "                      header=True\n",
        "                      )"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JccM_5SQilIz"
      },
      "source": [
        "# 4.1 Obviously there are problems \n",
        "data.show()\n",
        "data.count()    # 6792"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btxEAW69isTa"
      },
      "source": [
        "The mismatch between pandas read and pyspark read, necessiates examinig data closely. On examining data one finds that there are many sentences, as below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9s6uvbbi-Jf"
      },
      "source": [
        "```\n",
        "7,44959,,03-03-2020,Voting in the age of #coronavirus = hand sanitizer ? #SuperTuesday https://t.co/z0BeL4O6Dk,Positive\n",
        "8,44960,\"Geneva, Switzerland\",03-03-2020,\"@DrTedros \"\"We canÂ’t stop #COVID19 without protecting #healthworkers.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSBz4vBijBtJ"
      },
      "source": [
        "The above is an extract from a single tweet. Ihe tweet is on multiple lines and also having <u>double</u>, double-inverted-commas. This complicates reading in pyspark. The solution is presented in StackOverflow at [this link](https://stackoverflow.com/a/69126284). We, therefore, proceed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWvTt-VqVwTs"
      },
      "source": [
        "# 4.2 First define a Spark schema\n",
        "schema = StructType([ \\\n",
        "                     StructField(\"UserName\",StringType(),True), \\\n",
        "                     StructField(\"ScreenName\",StringType(),True), \\\n",
        "                     StructField(\"Location\",StringType(),True), \\\n",
        "                     StructField(\"TweetAt\", StringType(), True), \\\n",
        "                     StructField(\"OriginalTweet\", StringType(), True), \\\n",
        "                     StructField(\"Sentiment\", StringType(), True) \\\n",
        "  ])\n",
        " "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMm8ctqxablQ"
      },
      "source": [
        "# 4.3 Next tead the data\n",
        "df = spark.read  \\\n",
        "                 .option(\"quote\", \"\\\"\") \\\n",
        "                 .option('escape', \"\\\"\") \\\n",
        "                 .option(\"multiLine\", \"true\")  \\\n",
        "                 .option(\"schema\" , schema)  \\\n",
        "                 .option(\"header\", \"true\") \\\n",
        "                 .csv(path)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JK20rJqjviT"
      },
      "source": [
        "# 4.4 The result shows complete match with pandas:\n",
        "df.show()\n",
        "df.count()    # 3798"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayvalhVDj-Pk"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQgRvDKWb8I"
      },
      "source": [
        "# 4.5\n",
        "df= df.select('OriginalTweet', 'Sentiment')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cth2225hlIvp"
      },
      "source": [
        "# Rename columns as suggested by spark-nlp\n",
        "df = df.withColumn(\n",
        "                    \"label\",\n",
        "                    df[\"Sentiment\"]\n",
        "                                    )\n",
        "\n",
        "df = df.withColumn(\n",
        "                    \"text\",\n",
        "                     df[\"OriginalTweet\"]\n",
        "                   )\n",
        "\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnP5UyWqnUvb"
      },
      "source": [
        "df = df.replace('Extremely Negative', 'Negative')\n",
        "df = df.replace('Extremely Positive', 'Positive')\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dIdvDbhkw7o"
      },
      "source": [
        "# Split data\n",
        "train,test = df.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCG_BLlVcH8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36d9958-d58f-4600-c7a5-c96ef42a6486"
      },
      "source": [
        "train.count()   # 3067\n",
        "print(\"\\n\")\n",
        "test.count()    # 731"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3037"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "761"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl5JwOARlqFd"
      },
      "source": [
        "## Process as spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcF-JxFTdxcN"
      },
      "source": [
        "# Create DocumentAssembler Object:\n",
        "\n",
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5zx-2_yi_kR",
        "outputId": "c7c27155-ff0c-4db2-8fda-ded10adcbeae"
      },
      "source": [
        "# Transform document in Word2vec space:\n",
        "# There is download of around 970mb:\n",
        "\n",
        "useEmbeddings = UniversalSentenceEncoder.pretrained() \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"sentence_embeddings\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTc7_-m2jDdR"
      },
      "source": [
        "# Define classifier object:\n",
        "\n",
        "docClassifier = ClassifierDLApproach() \\\n",
        "    .setInputCols(\"sentence_embeddings\") \\\n",
        "    .setOutputCol(\"category\") \\\n",
        "    .setLabelColumn(\"label\") \\\n",
        "    .setBatchSize(64) \\\n",
        "    .setMaxEpochs(20) \\\n",
        "    .setLr(5e-3) \\\n",
        "    .setDropout(0.5)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOMit9zRRI2b"
      },
      "source": [
        "# Create pipeline:\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "    .setStages(\n",
        "      [\n",
        "        documentAssembler,\n",
        "        useEmbeddings,\n",
        "        docClassifier\n",
        "      ]\n",
        "    )"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1CH_h60jH4S"
      },
      "source": [
        "# Create model:\n",
        "pipelineModel = pipeline.fit(train)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIXEmRDReNLA"
      },
      "source": [
        "# MAke predictions for test data:\n",
        "\n",
        "pred = pipelineModel.transform(test)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot35G91JldxZ",
        "outputId": "b372472d-953c-448e-be8a-039cd728ecac"
      },
      "source": [
        "pred.columns"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OriginalTweet',\n",
              " 'Sentiment',\n",
              " 'label',\n",
              " 'text',\n",
              " 'document',\n",
              " 'sentence_embeddings',\n",
              " 'category']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ShNvWAlhtx"
      },
      "source": [
        "pred.select('label','category').show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqxm3e7qpb1J"
      },
      "source": [
        "# Ref: https://nlp.johnsnowlabs.com/docs/en/annotators#finisher\n",
        "finisher = Finisher().setInputCols(\"category\").setOutputCols(\"output\")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzUYvu1pp4Di"
      },
      "source": [
        "result = finisher.transform(pred)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zroROuelqDH_",
        "outputId": "fea49e2e-a5c5-4cdf-f44f-9bd9be9d4abd"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OriginalTweet', 'Sentiment', 'label', 'text', 'output']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfx0C5IjmaZw"
      },
      "source": [
        "p = result.select('label', 'output').toPandas()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk5l6qPimgJw"
      },
      "source": [
        "p = p.explode('output')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CjMSYYFrWgu",
        "outputId": "31444f29-5ed3-41f5-cd2f-7d6d2bafcb2b"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "np.sum((p.label == p.output))/p.shape[0]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6202365308804205"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}